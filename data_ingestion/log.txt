[28/06/2023 23:09:33] Converting 0_titanic.xlsx to CSV....
[28/06/2023 23:09:34] Converted sheet 0_titanic.complete to 0_titanic_complete.csv
[28/06/2023 23:09:34] Converted sheet 0_titanic.numeric to 0_titanic_numeric.csv
[28/06/2023 23:09:34] Converting 1_TOP500-Computing.xlsx to CSV....
[28/06/2023 23:09:34] Converted sheet 1_TOP500-Computing.61 to 1_TOP500-Computing_61.csv
[28/06/2023 23:09:34] Batch upload started.
[28/06/2023 23:09:34] Uploading 0_titanic_complete.csv
[28/06/2023 23:09:34] Writing metadata for 0_titanic_complete.csv.
[28/06/2023 23:09:34] Creating JSON spec for 0_titanic_complete.csv in datasets/1687973973_LotsofData//0_titanic_complete.csv.json
[28/06/2023 23:09:34] Druid Task Succeeded.
[28/06/2023 23:09:34] Uploading 0_titanic_numeric.csv
[28/06/2023 23:09:34] Writing metadata for 0_titanic_numeric.csv.
[28/06/2023 23:09:34] Creating JSON spec for 0_titanic_numeric.csv in datasets/1687973973_LotsofData//0_titanic_numeric.csv.json
[28/06/2023 23:09:34] Druid Task Succeeded.
[28/06/2023 23:09:34] Uploading 1_TOP500-Computing_61.csv
[28/06/2023 23:09:34] Writing metadata for 1_TOP500-Computing_61.csv.
[28/06/2023 23:09:34] Creating JSON spec for 1_TOP500-Computing_61.csv in datasets/1687973973_LotsofData//1_TOP500-Computing_61.csv.json
[28/06/2023 23:09:34] Druid Task Succeeded.
[28/06/2023 23:09:34] Uploading 2_nature-index-500.csv
[28/06/2023 23:09:34] Writing metadata for 2_nature-index-500.csv.
[28/06/2023 23:09:34] Creating JSON spec for 2_nature-index-500.csv in datasets/1687973973_LotsofData//2_nature-index-500.csv.json
[28/06/2023 23:09:35] Druid Task Succeeded.
[28/06/2023 23:19:24] Converting 0_titanic.xlsx to CSV....
[28/06/2023 23:19:24] Converted sheet 0_titanic.complete to 0_titanic_complete.csv
[28/06/2023 23:19:24] Converted sheet 0_titanic.numeric to 0_titanic_numeric.csv
[28/06/2023 23:19:24] Batch upload started.
[28/06/2023 23:19:24] Uploading 0_titanic_complete.csv
[28/06/2023 23:19:24] Writing metadata for 0_titanic_complete.csv.
[28/06/2023 23:19:24] Creating JSON spec for 0_titanic_complete.csv in datasets/1687974564_Test Dataset Dump//0_titanic_complete.csv.json
[28/06/2023 23:19:24] Druid Task Succeeded.
[28/06/2023 23:19:24] Uploading 0_titanic_numeric.csv
[28/06/2023 23:19:24] Writing metadata for 0_titanic_numeric.csv.
[28/06/2023 23:19:24] Creating JSON spec for 0_titanic_numeric.csv in datasets/1687974564_Test Dataset Dump//0_titanic_numeric.csv.json
[28/06/2023 23:19:24] Druid Task Succeeded.
[28/06/2023 23:25:13] Converting 0_titanic.xlsx to CSV....
[28/06/2023 23:25:14] Converted sheet 0_titanic.complete to 0_titanic_complete.csv
[28/06/2023 23:25:14] Converted sheet 0_titanic.numeric to 0_titanic_numeric.csv
[28/06/2023 23:25:14] Batch upload started.
[28/06/2023 23:25:14] Uploading 0_titanic_complete.csv
[28/06/2023 23:25:14] Writing metadata for 0_titanic_complete.csv.
[28/06/2023 23:25:14] Creating JSON spec for 0_titanic_complete.csv in datasets/1687974913_Titanic Test Data Set//0_titanic_complete.csv.json
[28/06/2023 23:25:14] Druid Task Succeeded.
[28/06/2023 23:25:14] Uploading 0_titanic_numeric.csv
[28/06/2023 23:25:14] Writing metadata for 0_titanic_numeric.csv.
[28/06/2023 23:25:14] Creating JSON spec for 0_titanic_numeric.csv in datasets/1687974913_Titanic Test Data Set//0_titanic_numeric.csv.json
[28/06/2023 23:25:14] Druid Task Succeeded.
[29/06/2023 11:27:29] Converting 0_sample-multisheet.xlsx to CSV....
[29/06/2023 11:27:29] Converted sheet 0_sample-multisheet.2018 to 0_sample-multisheet_2018.csv
[29/06/2023 11:27:29] Converted sheet 0_sample-multisheet.2019 to 0_sample-multisheet_2019.csv
[29/06/2023 11:27:29] Batch upload started.
[29/06/2023 11:27:29] Uploading 0_sample-multisheet_2018.csv
[29/06/2023 11:27:29] Writing metadata for 0_sample-multisheet_2018.csv.
[29/06/2023 11:27:29] Creating JSON spec for 0_sample-multisheet_2018.csv in datasets/1688018248_sample_multisheet//0_sample-multisheet_2018.csv.json
[29/06/2023 11:27:29] Druid Task Succeeded.
[29/06/2023 11:27:29] Uploading 0_sample-multisheet_2019.csv
[29/06/2023 11:27:29] Writing metadata for 0_sample-multisheet_2019.csv.
[29/06/2023 11:27:29] Creating JSON spec for 0_sample-multisheet_2019.csv in datasets/1688018248_sample_multisheet//0_sample-multisheet_2019.csv.json
[29/06/2023 11:27:29] Druid Task Succeeded.
[29/06/2023 11:54:24] Converted sheet 1688019864_titanic.complete to 1688019864_titanic_complete.csv
[29/06/2023 11:54:24] Converted sheet 1688019864_titanic.numeric to 1688019864_titanic_numeric.csv
[29/06/2023 11:54:24] Uploading file: 1688019864_titanic.xlsx
[29/06/2023 11:54:24] *** EXCEPTION ***
[29/06/2023 11:54:24] Traceback (most recent call last):
[29/06/2023 11:54:24]   File "/mnt/c/Users/winga/OneDrive/Desktop/KDL_SRIP23/data_ingestion/upload_single_druid.py", line 19, in <module>
[29/06/2023 11:54:24]     WriteMetaData(file)
[29/06/2023 11:54:24] TypeError: WriteMetaData() missing 1 required positional argument: 'path'
[29/06/2023 11:54:24] 
[29/06/2023 11:54:24] ***
[29/06/2023 11:56:04] Converted sheet 1688019963_titanic.complete to 1688019963_titanic_complete.csv
[29/06/2023 11:56:04] Converted sheet 1688019963_titanic.numeric to 1688019963_titanic_numeric.csv
[29/06/2023 11:56:04] Uploading file: 1688019963_titanic.xlsx
[29/06/2023 11:56:04] Writing metadata for 1688019963_titanic_complete.csv.
[29/06/2023 11:56:04] Creating JSON spec for 1688019963_titanic_complete.csv in datasets/1688019963_titanic_complete.csv.json
[29/06/2023 11:56:04] Druid Task Succeeded.
[29/06/2023 11:56:04] Writing metadata for 1688019963_titanic_numeric.csv.
[29/06/2023 11:56:04] Creating JSON spec for 1688019963_titanic_numeric.csv in datasets/1688019963_titanic_numeric.csv.json
[29/06/2023 11:56:04] Druid Task Succeeded.
[30/06/2023 03:06:47] Converted sheet 1688074606_titanic.complete to 1688074606_titanic_complete.csv
[30/06/2023 03:06:47] Converted sheet 1688074606_titanic.numeric to 1688074606_titanic_numeric.csv
[30/06/2023 03:06:47] Uploading file: 1688074606_titanic.xlsx
[30/06/2023 03:06:47] Writing metadata for 1688074606_titanic_complete.csv.
[30/06/2023 03:06:47] Creating JSON spec for 1688074606_titanic_complete.csv in datasets/1688074606_titanic_complete.csv.json
[30/06/2023 03:06:48] Druid Task Succeeded.
[30/06/2023 03:06:48] Writing metadata for 1688074606_titanic_numeric.csv.
[30/06/2023 03:06:48] Creating JSON spec for 1688074606_titanic_numeric.csv in datasets/1688074606_titanic_numeric.csv.json
[30/06/2023 03:06:48] Druid Task Succeeded.
[30/06/2023 03:12:45] Converted sheet 1688074964_titanic.complete to 1688074964_titanic_complete.csv
[30/06/2023 03:12:45] Converted sheet 1688074964_titanic.numeric to 1688074964_titanic_numeric.csv
[30/06/2023 03:12:45] Uploading file: 1688074964_titanic.xlsx
[30/06/2023 03:12:45] Writing metadata for 1688074964_titanic_complete.csv.
[30/06/2023 03:12:45] Creating JSON spec for 1688074964_titanic_complete.csv in datasets/1688074964_titanic_complete.csv.json
[30/06/2023 03:12:45] Druid Task Succeeded.
[30/06/2023 03:12:45] Writing metadata for 1688074964_titanic_numeric.csv.
[30/06/2023 03:12:45] Creating JSON spec for 1688074964_titanic_numeric.csv in datasets/1688074964_titanic_numeric.csv.json
[30/06/2023 03:12:45] Druid Task Succeeded.
[04/07/2023 13:12:42] *** EXCEPTION ***
[04/07/2023 13:12:42] Traceback (most recent call last):
[04/07/2023 13:12:42]   File "/home/sgautam/.local/lib/python3.10/site-packages/pandas/compat/_optional.py", line 142, in import_optional_dependency
[04/07/2023 13:12:42]     module = importlib.import_module(name)
[04/07/2023 13:12:42]   File "/usr/lib/python3.10/importlib/__init__.py", line 126, in import_module
[04/07/2023 13:12:42]     return _bootstrap._gcd_import(name[level:], package, level)
[04/07/2023 13:12:42]   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
[04/07/2023 13:12:42]   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
[04/07/2023 13:12:42]   File "<frozen importlib._bootstrap>", line 1004, in _find_and_load_unlocked
[04/07/2023 13:12:42] ModuleNotFoundError: No module named 'openpyxl'
[04/07/2023 13:12:42] 
[04/07/2023 13:12:42] During handling of the above exception, another exception occurred:
[04/07/2023 13:12:42] 
[04/07/2023 13:12:42] Traceback (most recent call last):
[04/07/2023 13:12:42]   File "/mnt/c/Users/winga/OneDrive/Desktop/KDL_SRIP23/data_ingestion/xlsx2csv.py", line 13, in convert2CSV
[04/07/2023 13:12:42]     xlsx_file = pandas.ExcelFile(xlsx_dir + "/" + xlsx_name)
[04/07/2023 13:12:42]   File "/home/sgautam/.local/lib/python3.10/site-packages/pandas/io/excel/_base.py", line 1513, in __init__
[04/07/2023 13:12:42]     self._reader = self._engines[engine](self._io, storage_options=storage_options)
[04/07/2023 13:12:42]   File "/home/sgautam/.local/lib/python3.10/site-packages/pandas/io/excel/_openpyxl.py", line 548, in __init__
[04/07/2023 13:12:42]     import_optional_dependency("openpyxl")
[04/07/2023 13:12:42]   File "/home/sgautam/.local/lib/python3.10/site-packages/pandas/compat/_optional.py", line 145, in import_optional_dependency
[04/07/2023 13:12:42]     raise ImportError(msg)
[04/07/2023 13:12:42] ImportError: Missing optional dependency 'openpyxl'.  Use pip or conda to install openpyxl.
[04/07/2023 13:12:42] 
[04/07/2023 13:12:42] ***
[04/07/2023 13:12:42] Uploading file: 1688456562_titanic.xlsx
[04/07/2023 13:12:42] *** EXCEPTION ***
[04/07/2023 13:12:42] Traceback (most recent call last):
[04/07/2023 13:12:42]   File "/mnt/c/Users/winga/OneDrive/Desktop/KDL_SRIP23/data_ingestion/upload_single_druid.py", line 18, in <module>
[04/07/2023 13:12:42]     for file in upload_data:
[04/07/2023 13:12:42] TypeError: 'NoneType' object is not iterable
[04/07/2023 13:12:42] 
[04/07/2023 13:12:42] ***
[04/07/2023 13:13:33] Converted sheet 1688456612_titanic.complete to 1688456612_titanic_complete.csv
[04/07/2023 13:13:33] Converted sheet 1688456612_titanic.numeric to 1688456612_titanic_numeric.csv
[04/07/2023 13:13:33] Uploading file: 1688456612_titanic.xlsx
[04/07/2023 13:13:33] Writing metadata for 1688456612_titanic_complete.csv.
[04/07/2023 13:13:33] Creating JSON spec for 1688456612_titanic_complete.csv in datasets/1688456612_titanic_complete.csv.json
[04/07/2023 13:13:33] Druid Task Succeeded.
[04/07/2023 13:13:33] Writing metadata for 1688456612_titanic_numeric.csv.
[04/07/2023 13:13:33] Creating JSON spec for 1688456612_titanic_numeric.csv in datasets/1688456612_titanic_numeric.csv.json
[04/07/2023 13:13:33] Druid Task Succeeded.
[04/07/2023 13:21:11] Converting 2_sample-multisheet.xlsx to CSV....
[04/07/2023 13:21:11] Converted sheet 2_sample-multisheet.2018 to 2_sample-multisheet_2018.csv
[04/07/2023 13:21:11] Converted sheet 2_sample-multisheet.2019 to 2_sample-multisheet_2019.csv
[04/07/2023 13:21:11] Converting 3_titanic.xlsx to CSV....
[04/07/2023 13:21:11] Converted sheet 3_titanic.complete to 3_titanic_complete.csv
[04/07/2023 13:21:11] Converted sheet 3_titanic.numeric to 3_titanic_numeric.csv
[04/07/2023 13:21:11] Batch upload started.
[04/07/2023 13:21:11] Uploading 0_world-forecast.csv
[04/07/2023 13:21:11] Writing metadata for 0_world-forecast.csv.
[04/07/2023 13:21:11] Creating JSON spec for 0_world-forecast.csv in datasets/1688457071_open system data//0_world-forecast.csv.json
[04/07/2023 13:21:11] Druid Task Succeeded.
[04/07/2023 13:21:11] Uploading 1_nature-index-500.csv
[04/07/2023 13:21:11] Writing metadata for 1_nature-index-500.csv.
[04/07/2023 13:21:11] Creating JSON spec for 1_nature-index-500.csv in datasets/1688457071_open system data//1_nature-index-500.csv.json
[04/07/2023 13:21:11] Druid Task Succeeded.
[04/07/2023 13:21:11] Uploading 2_sample-multisheet_2018.csv
[04/07/2023 13:21:11] Writing metadata for 2_sample-multisheet_2018.csv.
[04/07/2023 13:21:11] Creating JSON spec for 2_sample-multisheet_2018.csv in datasets/1688457071_open system data//2_sample-multisheet_2018.csv.json
[04/07/2023 13:21:11] Druid Task Succeeded.
[04/07/2023 13:21:11] Uploading 2_sample-multisheet_2019.csv
[04/07/2023 13:21:11] Writing metadata for 2_sample-multisheet_2019.csv.
[04/07/2023 13:21:11] Creating JSON spec for 2_sample-multisheet_2019.csv in datasets/1688457071_open system data//2_sample-multisheet_2019.csv.json
[04/07/2023 13:21:11] Druid Task Succeeded.
[04/07/2023 13:21:11] Uploading 3_titanic_complete.csv
[04/07/2023 13:21:11] Writing metadata for 3_titanic_complete.csv.
[04/07/2023 13:21:12] Creating JSON spec for 3_titanic_complete.csv in datasets/1688457071_open system data//3_titanic_complete.csv.json
[04/07/2023 13:21:12] Druid Task Succeeded.
[04/07/2023 13:21:12] Uploading 3_titanic_numeric.csv
[04/07/2023 13:21:12] Writing metadata for 3_titanic_numeric.csv.
[04/07/2023 13:21:12] Creating JSON spec for 3_titanic_numeric.csv in datasets/1688457071_open system data//3_titanic_numeric.csv.json
[04/07/2023 13:21:12] Druid Task Succeeded.
[12/07/2023 17:24:26] Batch upload started.
[12/07/2023 17:35:17] *** EXCEPTION ***
[12/07/2023 17:35:17] Traceback (most recent call last):
[12/07/2023 17:35:17]   File "/mnt/c/Users/winga/OneDrive/Desktop/repos/KDL_SRIP23/data_ingestion/fetch_rows.py", line 11, in <module>
[12/07/2023 17:35:17]     df = df.drop(['KDL_METADATA'], axis=1)
[12/07/2023 17:35:17]   File "/home/sgautam/.local/lib/python3.10/site-packages/pandas/core/frame.py", line 5258, in drop
[12/07/2023 17:35:17]     return super().drop(
[12/07/2023 17:35:17]   File "/home/sgautam/.local/lib/python3.10/site-packages/pandas/core/generic.py", line 4549, in drop
[12/07/2023 17:35:17]     obj = obj._drop_axis(labels, axis, level=level, errors=errors)
[12/07/2023 17:35:17]   File "/home/sgautam/.local/lib/python3.10/site-packages/pandas/core/generic.py", line 4591, in _drop_axis
[12/07/2023 17:35:17]     new_axis = axis.drop(labels, errors=errors)
[12/07/2023 17:35:17]   File "/home/sgautam/.local/lib/python3.10/site-packages/pandas/core/indexes/base.py", line 6699, in drop
[12/07/2023 17:35:17]     raise KeyError(f"{list(labels[mask])} not found in axis")
[12/07/2023 17:35:17] KeyError: "['KDL_METADATA'] not found in axis"
[12/07/2023 17:35:17] 
[12/07/2023 17:35:17] ***
[12/07/2023 22:40:08] Uploading file: 1689181807_KAG_HEALTH.csv
[12/07/2023 22:40:08] Writing metadata for 1689181807_KAG_HEALTH.csv.
[12/07/2023 22:40:08] Creating JSON spec for 1689181807_KAG_HEALTH.csv in datasets/1689181807_KAG_HEALTH.csv.json
[12/07/2023 22:40:08] Druid Task Succeeded.
[12/07/2023 22:48:33] Uploading file: 1689182313_AGRICULTURE_CENSUS_HOLDINGS.csv
[12/07/2023 22:48:33] Writing metadata for 1689182313_AGRICULTURE_CENSUS_HOLDINGS.csv.
[12/07/2023 22:48:33] Creating JSON spec for 1689182313_AGRICULTURE_CENSUS_HOLDINGS.csv in datasets/1689182313_AGRICULTURE_CENSUS_HOLDINGS.csv.json
[12/07/2023 22:48:33] Druid Task Succeeded.
[12/07/2023 22:52:05] Uploading file: 1689182525_AGRICULTURE_CENSUS_HOLDINGS.csv
[12/07/2023 22:52:05] Writing metadata for 1689182525_AGRICULTURE_CENSUS_HOLDINGS.csv.
[12/07/2023 22:52:05] Creating JSON spec for 1689182525_AGRICULTURE_CENSUS_HOLDINGS.csv in datasets/1689182525_AGRICULTURE_CENSUS_HOLDINGS.csv.json
[12/07/2023 22:52:05] Druid Task Succeeded.
[12/07/2023 22:55:08] Uploading file: 1689182708_AGRICULTURE_CENSUS_HOLDINGS.csv
[12/07/2023 22:55:08] Writing metadata for 1689182708_AGRICULTURE_CENSUS_HOLDINGS.csv.
[12/07/2023 22:55:08] Creating JSON spec for 1689182708_AGRICULTURE_CENSUS_HOLDINGS.csv in datasets/1689182708_AGRICULTURE_CENSUS_HOLDINGS.csv.json
[12/07/2023 22:55:09] Druid Task Succeeded.
[12/07/2023 23:11:59] Converting 1_titanic.xlsx to CSV....
[12/07/2023 23:11:59] Converted sheet 1_titanic.complete to 1_titanic_complete.csv
[12/07/2023 23:11:59] Converted sheet 1_titanic.numeric to 1_titanic_numeric.csv
[12/07/2023 23:11:59] Converting 3_TOP500-Computing.xlsx to CSV....
[12/07/2023 23:11:59] Converted sheet 3_TOP500-Computing.61 to 3_TOP500-Computing_61.csv
[12/07/2023 23:11:59] Batch upload started.
[12/07/2023 23:11:59] Uploading 0_nature-index-500.csv
[12/07/2023 23:11:59] Writing metadata for 0_nature-index-500.csv.
[12/07/2023 23:11:59] Creating JSON spec for 0_nature-index-500.csv in datasets/1689183718_datadump test//0_nature-index-500.csv.json
[12/07/2023 23:11:59] Druid Task Succeeded.
[12/07/2023 23:11:59] Uploading 1_titanic_complete.csv
[12/07/2023 23:11:59] Writing metadata for 1_titanic_complete.csv.
[12/07/2023 23:11:59] Creating JSON spec for 1_titanic_complete.csv in datasets/1689183718_datadump test//1_titanic_complete.csv.json
[12/07/2023 23:12:00] Druid Task Succeeded.
[12/07/2023 23:12:00] Uploading 1_titanic_numeric.csv
[12/07/2023 23:12:00] Writing metadata for 1_titanic_numeric.csv.
[12/07/2023 23:12:00] Creating JSON spec for 1_titanic_numeric.csv in datasets/1689183718_datadump test//1_titanic_numeric.csv.json
[12/07/2023 23:12:00] Druid Task Succeeded.
[12/07/2023 23:12:00] Uploading 2_world-forecast.csv
[12/07/2023 23:12:00] Writing metadata for 2_world-forecast.csv.
[12/07/2023 23:12:00] Creating JSON spec for 2_world-forecast.csv in datasets/1689183718_datadump test//2_world-forecast.csv.json
[12/07/2023 23:12:00] Druid Task Succeeded.
[12/07/2023 23:12:00] Uploading 3_TOP500-Computing_61.csv
[12/07/2023 23:12:00] Writing metadata for 3_TOP500-Computing_61.csv.
[12/07/2023 23:12:00] Creating JSON spec for 3_TOP500-Computing_61.csv in datasets/1689183718_datadump test//3_TOP500-Computing_61.csv.json
[12/07/2023 23:12:00] Druid Task Succeeded.
[12/07/2023 23:14:19] Batch upload started.
[12/07/2023 23:14:52] Batch upload started.
[12/07/2023 23:18:34] Batch upload started.
[12/07/2023 23:19:18] Batch upload started.
[12/07/2023 23:26:16] Converting 1_titanic.xlsx to CSV....
[12/07/2023 23:26:16] Converted sheet 1_titanic.complete to 1_titanic_complete.csv
[12/07/2023 23:26:16] Converted sheet 1_titanic.numeric to 1_titanic_numeric.csv
[12/07/2023 23:26:16] Converting 2_TOP500-Computing.xlsx to CSV....
[12/07/2023 23:26:16] Converted sheet 2_TOP500-Computing.61 to 2_TOP500-Computing_61.csv
[12/07/2023 23:26:16] Batch upload started.
[12/07/2023 23:26:16] Uploading 0_nature-index-500.csv
[12/07/2023 23:26:16] Writing metadata for 0_nature-index-500.csv.
[12/07/2023 23:26:16] Creating JSON spec for 0_nature-index-500.csv in datasets/1689184575_newdatadump00//0_nature-index-500.csv.json
[12/07/2023 23:26:16] Druid Task Succeeded.
[12/07/2023 23:26:16] Uploading 1_titanic_complete.csv
[12/07/2023 23:26:16] Writing metadata for 1_titanic_complete.csv.
[12/07/2023 23:26:16] Creating JSON spec for 1_titanic_complete.csv in datasets/1689184575_newdatadump00//1_titanic_complete.csv.json
[12/07/2023 23:26:16] Druid Task Succeeded.
[12/07/2023 23:26:16] Uploading 1_titanic_numeric.csv
[12/07/2023 23:26:16] Writing metadata for 1_titanic_numeric.csv.
[12/07/2023 23:26:16] Creating JSON spec for 1_titanic_numeric.csv in datasets/1689184575_newdatadump00//1_titanic_numeric.csv.json
[12/07/2023 23:26:16] Druid Task Succeeded.
[12/07/2023 23:26:16] Uploading 2_TOP500-Computing_61.csv
[12/07/2023 23:26:16] Writing metadata for 2_TOP500-Computing_61.csv.
[12/07/2023 23:26:16] Creating JSON spec for 2_TOP500-Computing_61.csv in datasets/1689184575_newdatadump00//2_TOP500-Computing_61.csv.json
[12/07/2023 23:26:16] Druid Task Succeeded.
[12/07/2023 23:26:34] Batch upload started.
[12/07/2023 23:30:00] Batch upload started.
[12/07/2023 23:31:49] Batch upload started.
[12/07/2023 23:33:02] Batch upload started.
[12/07/2023 23:33:11] Batch upload started.
[12/07/2023 23:36:08] Converting 0_TOP500-Computing.xlsx to CSV....
[12/07/2023 23:36:08] Converted sheet 0_TOP500-Computing.61 to 0_TOP500-Computing_61.csv
[12/07/2023 23:36:08] Batch upload started.
[12/07/2023 23:36:08] Uploading 0_TOP500-Computing_61.csv
[12/07/2023 23:36:08] Writing metadata for 0_TOP500-Computing_61.csv.
[12/07/2023 23:36:08] Creating JSON spec for 0_TOP500-Computing_61.csv in datasets/1689185168_Test_Data_Dump//0_TOP500-Computing_61.csv.json
[12/07/2023 23:36:08] Druid Task Succeeded.
[12/07/2023 23:36:08] Uploading 1_nature-index-500.csv
[12/07/2023 23:36:08] Writing metadata for 1_nature-index-500.csv.
[12/07/2023 23:36:09] Creating JSON spec for 1_nature-index-500.csv in datasets/1689185168_Test_Data_Dump//1_nature-index-500.csv.json
[12/07/2023 23:36:09] Druid Task Succeeded.
[12/07/2023 23:36:09] Uploading 2_world-forecast.csv
[12/07/2023 23:36:09] Writing metadata for 2_world-forecast.csv.
[12/07/2023 23:36:09] Creating JSON spec for 2_world-forecast.csv in datasets/1689185168_Test_Data_Dump//2_world-forecast.csv.json
[12/07/2023 23:36:09] Druid Task Succeeded.
