[28/06/2023 23:09:33] Converting 0_titanic.xlsx to CSV....
[28/06/2023 23:09:34] Converted sheet 0_titanic.complete to 0_titanic_complete.csv
[28/06/2023 23:09:34] Converted sheet 0_titanic.numeric to 0_titanic_numeric.csv
[28/06/2023 23:09:34] Converting 1_TOP500-Computing.xlsx to CSV....
[28/06/2023 23:09:34] Converted sheet 1_TOP500-Computing.61 to 1_TOP500-Computing_61.csv
[28/06/2023 23:09:34] Batch upload started.
[28/06/2023 23:09:34] Uploading 0_titanic_complete.csv
[28/06/2023 23:09:34] Writing metadata for 0_titanic_complete.csv.
[28/06/2023 23:09:34] Creating JSON spec for 0_titanic_complete.csv in datasets/1687973973_LotsofData//0_titanic_complete.csv.json
[28/06/2023 23:09:34] Druid Task Succeeded.
[28/06/2023 23:09:34] Uploading 0_titanic_numeric.csv
[28/06/2023 23:09:34] Writing metadata for 0_titanic_numeric.csv.
[28/06/2023 23:09:34] Creating JSON spec for 0_titanic_numeric.csv in datasets/1687973973_LotsofData//0_titanic_numeric.csv.json
[28/06/2023 23:09:34] Druid Task Succeeded.
[28/06/2023 23:09:34] Uploading 1_TOP500-Computing_61.csv
[28/06/2023 23:09:34] Writing metadata for 1_TOP500-Computing_61.csv.
[28/06/2023 23:09:34] Creating JSON spec for 1_TOP500-Computing_61.csv in datasets/1687973973_LotsofData//1_TOP500-Computing_61.csv.json
[28/06/2023 23:09:34] Druid Task Succeeded.
[28/06/2023 23:09:34] Uploading 2_nature-index-500.csv
[28/06/2023 23:09:34] Writing metadata for 2_nature-index-500.csv.
[28/06/2023 23:09:34] Creating JSON spec for 2_nature-index-500.csv in datasets/1687973973_LotsofData//2_nature-index-500.csv.json
[28/06/2023 23:09:35] Druid Task Succeeded.
[28/06/2023 23:19:24] Converting 0_titanic.xlsx to CSV....
[28/06/2023 23:19:24] Converted sheet 0_titanic.complete to 0_titanic_complete.csv
[28/06/2023 23:19:24] Converted sheet 0_titanic.numeric to 0_titanic_numeric.csv
[28/06/2023 23:19:24] Batch upload started.
[28/06/2023 23:19:24] Uploading 0_titanic_complete.csv
[28/06/2023 23:19:24] Writing metadata for 0_titanic_complete.csv.
[28/06/2023 23:19:24] Creating JSON spec for 0_titanic_complete.csv in datasets/1687974564_Test Dataset Dump//0_titanic_complete.csv.json
[28/06/2023 23:19:24] Druid Task Succeeded.
[28/06/2023 23:19:24] Uploading 0_titanic_numeric.csv
[28/06/2023 23:19:24] Writing metadata for 0_titanic_numeric.csv.
[28/06/2023 23:19:24] Creating JSON spec for 0_titanic_numeric.csv in datasets/1687974564_Test Dataset Dump//0_titanic_numeric.csv.json
[28/06/2023 23:19:24] Druid Task Succeeded.
[28/06/2023 23:25:13] Converting 0_titanic.xlsx to CSV....
[28/06/2023 23:25:14] Converted sheet 0_titanic.complete to 0_titanic_complete.csv
[28/06/2023 23:25:14] Converted sheet 0_titanic.numeric to 0_titanic_numeric.csv
[28/06/2023 23:25:14] Batch upload started.
[28/06/2023 23:25:14] Uploading 0_titanic_complete.csv
[28/06/2023 23:25:14] Writing metadata for 0_titanic_complete.csv.
[28/06/2023 23:25:14] Creating JSON spec for 0_titanic_complete.csv in datasets/1687974913_Titanic Test Data Set//0_titanic_complete.csv.json
[28/06/2023 23:25:14] Druid Task Succeeded.
[28/06/2023 23:25:14] Uploading 0_titanic_numeric.csv
[28/06/2023 23:25:14] Writing metadata for 0_titanic_numeric.csv.
[28/06/2023 23:25:14] Creating JSON spec for 0_titanic_numeric.csv in datasets/1687974913_Titanic Test Data Set//0_titanic_numeric.csv.json
[28/06/2023 23:25:14] Druid Task Succeeded.
[29/06/2023 11:27:29] Converting 0_sample-multisheet.xlsx to CSV....
[29/06/2023 11:27:29] Converted sheet 0_sample-multisheet.2018 to 0_sample-multisheet_2018.csv
[29/06/2023 11:27:29] Converted sheet 0_sample-multisheet.2019 to 0_sample-multisheet_2019.csv
[29/06/2023 11:27:29] Batch upload started.
[29/06/2023 11:27:29] Uploading 0_sample-multisheet_2018.csv
[29/06/2023 11:27:29] Writing metadata for 0_sample-multisheet_2018.csv.
[29/06/2023 11:27:29] Creating JSON spec for 0_sample-multisheet_2018.csv in datasets/1688018248_sample_multisheet//0_sample-multisheet_2018.csv.json
[29/06/2023 11:27:29] Druid Task Succeeded.
[29/06/2023 11:27:29] Uploading 0_sample-multisheet_2019.csv
[29/06/2023 11:27:29] Writing metadata for 0_sample-multisheet_2019.csv.
[29/06/2023 11:27:29] Creating JSON spec for 0_sample-multisheet_2019.csv in datasets/1688018248_sample_multisheet//0_sample-multisheet_2019.csv.json
[29/06/2023 11:27:29] Druid Task Succeeded.
[29/06/2023 11:54:24] Converted sheet 1688019864_titanic.complete to 1688019864_titanic_complete.csv
[29/06/2023 11:54:24] Converted sheet 1688019864_titanic.numeric to 1688019864_titanic_numeric.csv
[29/06/2023 11:54:24] Uploading file: 1688019864_titanic.xlsx
[29/06/2023 11:54:24] *** EXCEPTION ***
[29/06/2023 11:54:24] Traceback (most recent call last):
[29/06/2023 11:54:24]   File "/mnt/c/Users/winga/OneDrive/Desktop/KDL_SRIP23/data_ingestion/upload_single_druid.py", line 19, in <module>
[29/06/2023 11:54:24]     WriteMetaData(file)
[29/06/2023 11:54:24] TypeError: WriteMetaData() missing 1 required positional argument: 'path'
[29/06/2023 11:54:24] 
[29/06/2023 11:54:24] ***
[29/06/2023 11:56:04] Converted sheet 1688019963_titanic.complete to 1688019963_titanic_complete.csv
[29/06/2023 11:56:04] Converted sheet 1688019963_titanic.numeric to 1688019963_titanic_numeric.csv
[29/06/2023 11:56:04] Uploading file: 1688019963_titanic.xlsx
[29/06/2023 11:56:04] Writing metadata for 1688019963_titanic_complete.csv.
[29/06/2023 11:56:04] Creating JSON spec for 1688019963_titanic_complete.csv in datasets/1688019963_titanic_complete.csv.json
[29/06/2023 11:56:04] Druid Task Succeeded.
[29/06/2023 11:56:04] Writing metadata for 1688019963_titanic_numeric.csv.
[29/06/2023 11:56:04] Creating JSON spec for 1688019963_titanic_numeric.csv in datasets/1688019963_titanic_numeric.csv.json
[29/06/2023 11:56:04] Druid Task Succeeded.
[30/06/2023 03:06:47] Converted sheet 1688074606_titanic.complete to 1688074606_titanic_complete.csv
[30/06/2023 03:06:47] Converted sheet 1688074606_titanic.numeric to 1688074606_titanic_numeric.csv
[30/06/2023 03:06:47] Uploading file: 1688074606_titanic.xlsx
[30/06/2023 03:06:47] Writing metadata for 1688074606_titanic_complete.csv.
[30/06/2023 03:06:47] Creating JSON spec for 1688074606_titanic_complete.csv in datasets/1688074606_titanic_complete.csv.json
[30/06/2023 03:06:48] Druid Task Succeeded.
[30/06/2023 03:06:48] Writing metadata for 1688074606_titanic_numeric.csv.
[30/06/2023 03:06:48] Creating JSON spec for 1688074606_titanic_numeric.csv in datasets/1688074606_titanic_numeric.csv.json
[30/06/2023 03:06:48] Druid Task Succeeded.
[30/06/2023 03:12:45] Converted sheet 1688074964_titanic.complete to 1688074964_titanic_complete.csv
[30/06/2023 03:12:45] Converted sheet 1688074964_titanic.numeric to 1688074964_titanic_numeric.csv
[30/06/2023 03:12:45] Uploading file: 1688074964_titanic.xlsx
[30/06/2023 03:12:45] Writing metadata for 1688074964_titanic_complete.csv.
[30/06/2023 03:12:45] Creating JSON spec for 1688074964_titanic_complete.csv in datasets/1688074964_titanic_complete.csv.json
[30/06/2023 03:12:45] Druid Task Succeeded.
[30/06/2023 03:12:45] Writing metadata for 1688074964_titanic_numeric.csv.
[30/06/2023 03:12:45] Creating JSON spec for 1688074964_titanic_numeric.csv in datasets/1688074964_titanic_numeric.csv.json
[30/06/2023 03:12:45] Druid Task Succeeded.
[04/07/2023 13:12:42] *** EXCEPTION ***
[04/07/2023 13:12:42] Traceback (most recent call last):
[04/07/2023 13:12:42]   File "/home/sgautam/.local/lib/python3.10/site-packages/pandas/compat/_optional.py", line 142, in import_optional_dependency
[04/07/2023 13:12:42]     module = importlib.import_module(name)
[04/07/2023 13:12:42]   File "/usr/lib/python3.10/importlib/__init__.py", line 126, in import_module
[04/07/2023 13:12:42]     return _bootstrap._gcd_import(name[level:], package, level)
[04/07/2023 13:12:42]   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
[04/07/2023 13:12:42]   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
[04/07/2023 13:12:42]   File "<frozen importlib._bootstrap>", line 1004, in _find_and_load_unlocked
[04/07/2023 13:12:42] ModuleNotFoundError: No module named 'openpyxl'
[04/07/2023 13:12:42] 
[04/07/2023 13:12:42] During handling of the above exception, another exception occurred:
[04/07/2023 13:12:42] 
[04/07/2023 13:12:42] Traceback (most recent call last):
[04/07/2023 13:12:42]   File "/mnt/c/Users/winga/OneDrive/Desktop/KDL_SRIP23/data_ingestion/xlsx2csv.py", line 13, in convert2CSV
[04/07/2023 13:12:42]     xlsx_file = pandas.ExcelFile(xlsx_dir + "/" + xlsx_name)
[04/07/2023 13:12:42]   File "/home/sgautam/.local/lib/python3.10/site-packages/pandas/io/excel/_base.py", line 1513, in __init__
[04/07/2023 13:12:42]     self._reader = self._engines[engine](self._io, storage_options=storage_options)
[04/07/2023 13:12:42]   File "/home/sgautam/.local/lib/python3.10/site-packages/pandas/io/excel/_openpyxl.py", line 548, in __init__
[04/07/2023 13:12:42]     import_optional_dependency("openpyxl")
[04/07/2023 13:12:42]   File "/home/sgautam/.local/lib/python3.10/site-packages/pandas/compat/_optional.py", line 145, in import_optional_dependency
[04/07/2023 13:12:42]     raise ImportError(msg)
[04/07/2023 13:12:42] ImportError: Missing optional dependency 'openpyxl'.  Use pip or conda to install openpyxl.
[04/07/2023 13:12:42] 
[04/07/2023 13:12:42] ***
[04/07/2023 13:12:42] Uploading file: 1688456562_titanic.xlsx
[04/07/2023 13:12:42] *** EXCEPTION ***
[04/07/2023 13:12:42] Traceback (most recent call last):
[04/07/2023 13:12:42]   File "/mnt/c/Users/winga/OneDrive/Desktop/KDL_SRIP23/data_ingestion/upload_single_druid.py", line 18, in <module>
[04/07/2023 13:12:42]     for file in upload_data:
[04/07/2023 13:12:42] TypeError: 'NoneType' object is not iterable
[04/07/2023 13:12:42] 
[04/07/2023 13:12:42] ***
[04/07/2023 13:13:33] Converted sheet 1688456612_titanic.complete to 1688456612_titanic_complete.csv
[04/07/2023 13:13:33] Converted sheet 1688456612_titanic.numeric to 1688456612_titanic_numeric.csv
[04/07/2023 13:13:33] Uploading file: 1688456612_titanic.xlsx
[04/07/2023 13:13:33] Writing metadata for 1688456612_titanic_complete.csv.
[04/07/2023 13:13:33] Creating JSON spec for 1688456612_titanic_complete.csv in datasets/1688456612_titanic_complete.csv.json
[04/07/2023 13:13:33] Druid Task Succeeded.
[04/07/2023 13:13:33] Writing metadata for 1688456612_titanic_numeric.csv.
[04/07/2023 13:13:33] Creating JSON spec for 1688456612_titanic_numeric.csv in datasets/1688456612_titanic_numeric.csv.json
[04/07/2023 13:13:33] Druid Task Succeeded.
[04/07/2023 13:21:11] Converting 2_sample-multisheet.xlsx to CSV....
[04/07/2023 13:21:11] Converted sheet 2_sample-multisheet.2018 to 2_sample-multisheet_2018.csv
[04/07/2023 13:21:11] Converted sheet 2_sample-multisheet.2019 to 2_sample-multisheet_2019.csv
[04/07/2023 13:21:11] Converting 3_titanic.xlsx to CSV....
[04/07/2023 13:21:11] Converted sheet 3_titanic.complete to 3_titanic_complete.csv
[04/07/2023 13:21:11] Converted sheet 3_titanic.numeric to 3_titanic_numeric.csv
[04/07/2023 13:21:11] Batch upload started.
[04/07/2023 13:21:11] Uploading 0_world-forecast.csv
[04/07/2023 13:21:11] Writing metadata for 0_world-forecast.csv.
[04/07/2023 13:21:11] Creating JSON spec for 0_world-forecast.csv in datasets/1688457071_open system data//0_world-forecast.csv.json
[04/07/2023 13:21:11] Druid Task Succeeded.
[04/07/2023 13:21:11] Uploading 1_nature-index-500.csv
[04/07/2023 13:21:11] Writing metadata for 1_nature-index-500.csv.
[04/07/2023 13:21:11] Creating JSON spec for 1_nature-index-500.csv in datasets/1688457071_open system data//1_nature-index-500.csv.json
[04/07/2023 13:21:11] Druid Task Succeeded.
[04/07/2023 13:21:11] Uploading 2_sample-multisheet_2018.csv
[04/07/2023 13:21:11] Writing metadata for 2_sample-multisheet_2018.csv.
[04/07/2023 13:21:11] Creating JSON spec for 2_sample-multisheet_2018.csv in datasets/1688457071_open system data//2_sample-multisheet_2018.csv.json
[04/07/2023 13:21:11] Druid Task Succeeded.
[04/07/2023 13:21:11] Uploading 2_sample-multisheet_2019.csv
[04/07/2023 13:21:11] Writing metadata for 2_sample-multisheet_2019.csv.
[04/07/2023 13:21:11] Creating JSON spec for 2_sample-multisheet_2019.csv in datasets/1688457071_open system data//2_sample-multisheet_2019.csv.json
[04/07/2023 13:21:11] Druid Task Succeeded.
[04/07/2023 13:21:11] Uploading 3_titanic_complete.csv
[04/07/2023 13:21:11] Writing metadata for 3_titanic_complete.csv.
[04/07/2023 13:21:12] Creating JSON spec for 3_titanic_complete.csv in datasets/1688457071_open system data//3_titanic_complete.csv.json
[04/07/2023 13:21:12] Druid Task Succeeded.
[04/07/2023 13:21:12] Uploading 3_titanic_numeric.csv
[04/07/2023 13:21:12] Writing metadata for 3_titanic_numeric.csv.
[04/07/2023 13:21:12] Creating JSON spec for 3_titanic_numeric.csv in datasets/1688457071_open system data//3_titanic_numeric.csv.json
[04/07/2023 13:21:12] Druid Task Succeeded.
[12/07/2023 17:24:26] Batch upload started.
[12/07/2023 17:35:17] *** EXCEPTION ***
[12/07/2023 17:35:17] Traceback (most recent call last):
[12/07/2023 17:35:17]   File "/mnt/c/Users/winga/OneDrive/Desktop/repos/KDL_SRIP23/data_ingestion/fetch_rows.py", line 11, in <module>
[12/07/2023 17:35:17]     df = df.drop(['KDL_METADATA'], axis=1)
[12/07/2023 17:35:17]   File "/home/sgautam/.local/lib/python3.10/site-packages/pandas/core/frame.py", line 5258, in drop
[12/07/2023 17:35:17]     return super().drop(
[12/07/2023 17:35:17]   File "/home/sgautam/.local/lib/python3.10/site-packages/pandas/core/generic.py", line 4549, in drop
[12/07/2023 17:35:17]     obj = obj._drop_axis(labels, axis, level=level, errors=errors)
[12/07/2023 17:35:17]   File "/home/sgautam/.local/lib/python3.10/site-packages/pandas/core/generic.py", line 4591, in _drop_axis
[12/07/2023 17:35:17]     new_axis = axis.drop(labels, errors=errors)
[12/07/2023 17:35:17]   File "/home/sgautam/.local/lib/python3.10/site-packages/pandas/core/indexes/base.py", line 6699, in drop
[12/07/2023 17:35:17]     raise KeyError(f"{list(labels[mask])} not found in axis")
[12/07/2023 17:35:17] KeyError: "['KDL_METADATA'] not found in axis"
[12/07/2023 17:35:17] 
[12/07/2023 17:35:17] ***
[12/07/2023 22:40:08] Uploading file: 1689181807_KAG_HEALTH.csv
[12/07/2023 22:40:08] Writing metadata for 1689181807_KAG_HEALTH.csv.
[12/07/2023 22:40:08] Creating JSON spec for 1689181807_KAG_HEALTH.csv in datasets/1689181807_KAG_HEALTH.csv.json
[12/07/2023 22:40:08] Druid Task Succeeded.
[12/07/2023 22:48:33] Uploading file: 1689182313_AGRICULTURE_CENSUS_HOLDINGS.csv
[12/07/2023 22:48:33] Writing metadata for 1689182313_AGRICULTURE_CENSUS_HOLDINGS.csv.
[12/07/2023 22:48:33] Creating JSON spec for 1689182313_AGRICULTURE_CENSUS_HOLDINGS.csv in datasets/1689182313_AGRICULTURE_CENSUS_HOLDINGS.csv.json
[12/07/2023 22:48:33] Druid Task Succeeded.
[12/07/2023 22:52:05] Uploading file: 1689182525_AGRICULTURE_CENSUS_HOLDINGS.csv
[12/07/2023 22:52:05] Writing metadata for 1689182525_AGRICULTURE_CENSUS_HOLDINGS.csv.
[12/07/2023 22:52:05] Creating JSON spec for 1689182525_AGRICULTURE_CENSUS_HOLDINGS.csv in datasets/1689182525_AGRICULTURE_CENSUS_HOLDINGS.csv.json
[12/07/2023 22:52:05] Druid Task Succeeded.
[12/07/2023 22:55:08] Uploading file: 1689182708_AGRICULTURE_CENSUS_HOLDINGS.csv
[12/07/2023 22:55:08] Writing metadata for 1689182708_AGRICULTURE_CENSUS_HOLDINGS.csv.
[12/07/2023 22:55:08] Creating JSON spec for 1689182708_AGRICULTURE_CENSUS_HOLDINGS.csv in datasets/1689182708_AGRICULTURE_CENSUS_HOLDINGS.csv.json
[12/07/2023 22:55:09] Druid Task Succeeded.
[12/07/2023 23:11:59] Converting 1_titanic.xlsx to CSV....
[12/07/2023 23:11:59] Converted sheet 1_titanic.complete to 1_titanic_complete.csv
[12/07/2023 23:11:59] Converted sheet 1_titanic.numeric to 1_titanic_numeric.csv
[12/07/2023 23:11:59] Converting 3_TOP500-Computing.xlsx to CSV....
[12/07/2023 23:11:59] Converted sheet 3_TOP500-Computing.61 to 3_TOP500-Computing_61.csv
[12/07/2023 23:11:59] Batch upload started.
[12/07/2023 23:11:59] Uploading 0_nature-index-500.csv
[12/07/2023 23:11:59] Writing metadata for 0_nature-index-500.csv.
[12/07/2023 23:11:59] Creating JSON spec for 0_nature-index-500.csv in datasets/1689183718_datadump test//0_nature-index-500.csv.json
[12/07/2023 23:11:59] Druid Task Succeeded.
[12/07/2023 23:11:59] Uploading 1_titanic_complete.csv
[12/07/2023 23:11:59] Writing metadata for 1_titanic_complete.csv.
[12/07/2023 23:11:59] Creating JSON spec for 1_titanic_complete.csv in datasets/1689183718_datadump test//1_titanic_complete.csv.json
[12/07/2023 23:12:00] Druid Task Succeeded.
[12/07/2023 23:12:00] Uploading 1_titanic_numeric.csv
[12/07/2023 23:12:00] Writing metadata for 1_titanic_numeric.csv.
[12/07/2023 23:12:00] Creating JSON spec for 1_titanic_numeric.csv in datasets/1689183718_datadump test//1_titanic_numeric.csv.json
[12/07/2023 23:12:00] Druid Task Succeeded.
[12/07/2023 23:12:00] Uploading 2_world-forecast.csv
[12/07/2023 23:12:00] Writing metadata for 2_world-forecast.csv.
[12/07/2023 23:12:00] Creating JSON spec for 2_world-forecast.csv in datasets/1689183718_datadump test//2_world-forecast.csv.json
[12/07/2023 23:12:00] Druid Task Succeeded.
[12/07/2023 23:12:00] Uploading 3_TOP500-Computing_61.csv
[12/07/2023 23:12:00] Writing metadata for 3_TOP500-Computing_61.csv.
[12/07/2023 23:12:00] Creating JSON spec for 3_TOP500-Computing_61.csv in datasets/1689183718_datadump test//3_TOP500-Computing_61.csv.json
[12/07/2023 23:12:00] Druid Task Succeeded.
[12/07/2023 23:14:19] Batch upload started.
[12/07/2023 23:14:52] Batch upload started.
[12/07/2023 23:18:34] Batch upload started.
[12/07/2023 23:19:18] Batch upload started.
[12/07/2023 23:26:16] Converting 1_titanic.xlsx to CSV....
[12/07/2023 23:26:16] Converted sheet 1_titanic.complete to 1_titanic_complete.csv
[12/07/2023 23:26:16] Converted sheet 1_titanic.numeric to 1_titanic_numeric.csv
[12/07/2023 23:26:16] Converting 2_TOP500-Computing.xlsx to CSV....
[12/07/2023 23:26:16] Converted sheet 2_TOP500-Computing.61 to 2_TOP500-Computing_61.csv
[12/07/2023 23:26:16] Batch upload started.
[12/07/2023 23:26:16] Uploading 0_nature-index-500.csv
[12/07/2023 23:26:16] Writing metadata for 0_nature-index-500.csv.
[12/07/2023 23:26:16] Creating JSON spec for 0_nature-index-500.csv in datasets/1689184575_newdatadump00//0_nature-index-500.csv.json
[12/07/2023 23:26:16] Druid Task Succeeded.
[12/07/2023 23:26:16] Uploading 1_titanic_complete.csv
[12/07/2023 23:26:16] Writing metadata for 1_titanic_complete.csv.
[12/07/2023 23:26:16] Creating JSON spec for 1_titanic_complete.csv in datasets/1689184575_newdatadump00//1_titanic_complete.csv.json
[12/07/2023 23:26:16] Druid Task Succeeded.
[12/07/2023 23:26:16] Uploading 1_titanic_numeric.csv
[12/07/2023 23:26:16] Writing metadata for 1_titanic_numeric.csv.
[12/07/2023 23:26:16] Creating JSON spec for 1_titanic_numeric.csv in datasets/1689184575_newdatadump00//1_titanic_numeric.csv.json
[12/07/2023 23:26:16] Druid Task Succeeded.
[12/07/2023 23:26:16] Uploading 2_TOP500-Computing_61.csv
[12/07/2023 23:26:16] Writing metadata for 2_TOP500-Computing_61.csv.
[12/07/2023 23:26:16] Creating JSON spec for 2_TOP500-Computing_61.csv in datasets/1689184575_newdatadump00//2_TOP500-Computing_61.csv.json
[12/07/2023 23:26:16] Druid Task Succeeded.
[12/07/2023 23:26:34] Batch upload started.
[12/07/2023 23:30:00] Batch upload started.
[12/07/2023 23:31:49] Batch upload started.
[12/07/2023 23:33:02] Batch upload started.
[12/07/2023 23:33:11] Batch upload started.
[12/07/2023 23:36:08] Converting 0_TOP500-Computing.xlsx to CSV....
[12/07/2023 23:36:08] Converted sheet 0_TOP500-Computing.61 to 0_TOP500-Computing_61.csv
[12/07/2023 23:36:08] Batch upload started.
[12/07/2023 23:36:08] Uploading 0_TOP500-Computing_61.csv
[12/07/2023 23:36:08] Writing metadata for 0_TOP500-Computing_61.csv.
[12/07/2023 23:36:08] Creating JSON spec for 0_TOP500-Computing_61.csv in datasets/1689185168_Test_Data_Dump//0_TOP500-Computing_61.csv.json
[12/07/2023 23:36:08] Druid Task Succeeded.
[12/07/2023 23:36:08] Uploading 1_nature-index-500.csv
[12/07/2023 23:36:08] Writing metadata for 1_nature-index-500.csv.
[12/07/2023 23:36:09] Creating JSON spec for 1_nature-index-500.csv in datasets/1689185168_Test_Data_Dump//1_nature-index-500.csv.json
[12/07/2023 23:36:09] Druid Task Succeeded.
[12/07/2023 23:36:09] Uploading 2_world-forecast.csv
[12/07/2023 23:36:09] Writing metadata for 2_world-forecast.csv.
[12/07/2023 23:36:09] Creating JSON spec for 2_world-forecast.csv in datasets/1689185168_Test_Data_Dump//2_world-forecast.csv.json
[12/07/2023 23:36:09] Druid Task Succeeded.
[13/07/2023 14:51:06] *** EXCEPTION ***
[13/07/2023 14:51:06] Traceback (most recent call last):
[13/07/2023 14:51:06]   File "/home/sgautam/.local/lib/python3.10/site-packages/urllib3/connection.py", line 174, in _new_conn
[13/07/2023 14:51:06]     conn = connection.create_connection(
[13/07/2023 14:51:06]   File "/home/sgautam/.local/lib/python3.10/site-packages/urllib3/util/connection.py", line 95, in create_connection
[13/07/2023 14:51:06]     raise err
[13/07/2023 14:51:06]   File "/home/sgautam/.local/lib/python3.10/site-packages/urllib3/util/connection.py", line 85, in create_connection
[13/07/2023 14:51:06]     sock.connect(sa)
[13/07/2023 14:51:06] ConnectionRefusedError: [Errno 111] Connection refused
[13/07/2023 14:51:06] 
[13/07/2023 14:51:06] During handling of the above exception, another exception occurred:
[13/07/2023 14:51:06] 
[13/07/2023 14:51:06] Traceback (most recent call last):
[13/07/2023 14:51:06]   File "/home/sgautam/.local/lib/python3.10/site-packages/urllib3/connectionpool.py", line 714, in urlopen
[13/07/2023 14:51:06]     httplib_response = self._make_request(
[13/07/2023 14:51:06]   File "/home/sgautam/.local/lib/python3.10/site-packages/urllib3/connectionpool.py", line 415, in _make_request
[13/07/2023 14:51:06]     conn.request(method, url, **httplib_request_kw)
[13/07/2023 14:51:06]   File "/home/sgautam/.local/lib/python3.10/site-packages/urllib3/connection.py", line 244, in request
[13/07/2023 14:51:06]     super(HTTPConnection, self).request(method, url, body=body, headers=headers)
[13/07/2023 14:51:06]   File "/usr/lib/python3.10/http/client.py", line 1282, in request
[13/07/2023 14:51:06]     self._send_request(method, url, body, headers, encode_chunked)
[13/07/2023 14:51:06]   File "/usr/lib/python3.10/http/client.py", line 1328, in _send_request
[13/07/2023 14:51:06]     self.endheaders(body, encode_chunked=encode_chunked)
[13/07/2023 14:51:06]   File "/usr/lib/python3.10/http/client.py", line 1277, in endheaders
[13/07/2023 14:51:06]     self._send_output(message_body, encode_chunked=encode_chunked)
[13/07/2023 14:51:06]   File "/usr/lib/python3.10/http/client.py", line 1037, in _send_output
[13/07/2023 14:51:06]     self.send(msg)
[13/07/2023 14:51:06]   File "/usr/lib/python3.10/http/client.py", line 975, in send
[13/07/2023 14:51:06]     self.connect()
[13/07/2023 14:51:06]   File "/home/sgautam/.local/lib/python3.10/site-packages/urllib3/connection.py", line 205, in connect
[13/07/2023 14:51:06]     conn = self._new_conn()
[13/07/2023 14:51:06]   File "/home/sgautam/.local/lib/python3.10/site-packages/urllib3/connection.py", line 186, in _new_conn
[13/07/2023 14:51:06]     raise NewConnectionError(
[13/07/2023 14:51:06] urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x7f54ef483c10>: Failed to establish a new connection: [Errno 111] Connection refused
[13/07/2023 14:51:06] 
[13/07/2023 14:51:06] During handling of the above exception, another exception occurred:
[13/07/2023 14:51:06] 
[13/07/2023 14:51:06] Traceback (most recent call last):
[13/07/2023 14:51:06]   File "/home/sgautam/.local/lib/python3.10/site-packages/requests/adapters.py", line 486, in send
[13/07/2023 14:51:06]     resp = conn.urlopen(
[13/07/2023 14:51:06]   File "/home/sgautam/.local/lib/python3.10/site-packages/urllib3/connectionpool.py", line 798, in urlopen
[13/07/2023 14:51:06]     retries = retries.increment(
[13/07/2023 14:51:06]   File "/home/sgautam/.local/lib/python3.10/site-packages/urllib3/util/retry.py", line 592, in increment
[13/07/2023 14:51:06]     raise MaxRetryError(_pool, url, error or ResponseError(cause))
[13/07/2023 14:51:06] urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='localhost', port=8888): Max retries exceeded with url: /druid/v2/sql (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f54ef483c10>: Failed to establish a new connection: [Errno 111] Connection refused'))
[13/07/2023 14:51:06] 
[13/07/2023 14:51:06] During handling of the above exception, another exception occurred:
[13/07/2023 14:51:06] 
[13/07/2023 14:51:06] Traceback (most recent call last):
[13/07/2023 14:51:06]   File "/mnt/c/Users/winga/OneDrive/Desktop/repos/KDL_SRIP23/data_ingestion/fetch_rows.py", line 10, in <module>
[13/07/2023 14:51:06]     df = pydruid_helper.ExecuteSQLQuery(druid_query)
[13/07/2023 14:51:06]   File "/mnt/c/Users/winga/OneDrive/Desktop/repos/KDL_SRIP23/data_ingestion/pydruid_helper.py", line 8, in ExecuteSQLQuery
[13/07/2023 14:51:06]     json_data = requests.post(druid_url, json={"query": query}).json()
[13/07/2023 14:51:06]   File "/home/sgautam/.local/lib/python3.10/site-packages/requests/api.py", line 115, in post
[13/07/2023 14:51:06]     return request("post", url, data=data, json=json, **kwargs)
[13/07/2023 14:51:06]   File "/home/sgautam/.local/lib/python3.10/site-packages/requests/api.py", line 59, in request
[13/07/2023 14:51:06]     return session.request(method=method, url=url, **kwargs)
[13/07/2023 14:51:06]   File "/home/sgautam/.local/lib/python3.10/site-packages/requests/sessions.py", line 589, in request
[13/07/2023 14:51:06]     resp = self.send(prep, **send_kwargs)
[13/07/2023 14:51:06]   File "/home/sgautam/.local/lib/python3.10/site-packages/requests/sessions.py", line 703, in send
[13/07/2023 14:51:06]     r = adapter.send(request, **kwargs)
[13/07/2023 14:51:06]   File "/home/sgautam/.local/lib/python3.10/site-packages/requests/adapters.py", line 519, in send
[13/07/2023 14:51:06]     raise ConnectionError(e, request=request)
[13/07/2023 14:51:06] requests.exceptions.ConnectionError: HTTPConnectionPool(host='localhost', port=8888): Max retries exceeded with url: /druid/v2/sql (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f54ef483c10>: Failed to establish a new connection: [Errno 111] Connection refused'))
[13/07/2023 14:51:06] 
[13/07/2023 14:51:06] ***
[13/07/2023 14:51:45] *** EXCEPTION ***
[13/07/2023 14:51:45] Traceback (most recent call last):
[13/07/2023 14:51:45]   File "/home/sgautam/.local/lib/python3.10/site-packages/urllib3/connection.py", line 174, in _new_conn
[13/07/2023 14:51:45]     conn = connection.create_connection(
[13/07/2023 14:51:45]   File "/home/sgautam/.local/lib/python3.10/site-packages/urllib3/util/connection.py", line 95, in create_connection
[13/07/2023 14:51:45]     raise err
[13/07/2023 14:51:45]   File "/home/sgautam/.local/lib/python3.10/site-packages/urllib3/util/connection.py", line 85, in create_connection
[13/07/2023 14:51:45]     sock.connect(sa)
[13/07/2023 14:51:45] ConnectionRefusedError: [Errno 111] Connection refused
[13/07/2023 14:51:45] 
[13/07/2023 14:51:45] During handling of the above exception, another exception occurred:
[13/07/2023 14:51:45] 
[13/07/2023 14:51:45] Traceback (most recent call last):
[13/07/2023 14:51:45]   File "/home/sgautam/.local/lib/python3.10/site-packages/urllib3/connectionpool.py", line 714, in urlopen
[13/07/2023 14:51:45]     httplib_response = self._make_request(
[13/07/2023 14:51:45]   File "/home/sgautam/.local/lib/python3.10/site-packages/urllib3/connectionpool.py", line 415, in _make_request
[13/07/2023 14:51:45]     conn.request(method, url, **httplib_request_kw)
[13/07/2023 14:51:45]   File "/home/sgautam/.local/lib/python3.10/site-packages/urllib3/connection.py", line 244, in request
[13/07/2023 14:51:45]     super(HTTPConnection, self).request(method, url, body=body, headers=headers)
[13/07/2023 14:51:45]   File "/usr/lib/python3.10/http/client.py", line 1282, in request
[13/07/2023 14:51:45]     self._send_request(method, url, body, headers, encode_chunked)
[13/07/2023 14:51:45]   File "/usr/lib/python3.10/http/client.py", line 1328, in _send_request
[13/07/2023 14:51:45]     self.endheaders(body, encode_chunked=encode_chunked)
[13/07/2023 14:51:45]   File "/usr/lib/python3.10/http/client.py", line 1277, in endheaders
[13/07/2023 14:51:45]     self._send_output(message_body, encode_chunked=encode_chunked)
[13/07/2023 14:51:45]   File "/usr/lib/python3.10/http/client.py", line 1037, in _send_output
[13/07/2023 14:51:45]     self.send(msg)
[13/07/2023 14:51:45]   File "/usr/lib/python3.10/http/client.py", line 975, in send
[13/07/2023 14:51:45]     self.connect()
[13/07/2023 14:51:45]   File "/home/sgautam/.local/lib/python3.10/site-packages/urllib3/connection.py", line 205, in connect
[13/07/2023 14:51:45]     conn = self._new_conn()
[13/07/2023 14:51:45]   File "/home/sgautam/.local/lib/python3.10/site-packages/urllib3/connection.py", line 186, in _new_conn
[13/07/2023 14:51:45]     raise NewConnectionError(
[13/07/2023 14:51:45] urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x7fed082ffc10>: Failed to establish a new connection: [Errno 111] Connection refused
[13/07/2023 14:51:45] 
[13/07/2023 14:51:45] During handling of the above exception, another exception occurred:
[13/07/2023 14:51:45] 
[13/07/2023 14:51:45] Traceback (most recent call last):
[13/07/2023 14:51:45]   File "/home/sgautam/.local/lib/python3.10/site-packages/requests/adapters.py", line 486, in send
[13/07/2023 14:51:45]     resp = conn.urlopen(
[13/07/2023 14:51:45]   File "/home/sgautam/.local/lib/python3.10/site-packages/urllib3/connectionpool.py", line 798, in urlopen
[13/07/2023 14:51:45]     retries = retries.increment(
[13/07/2023 14:51:45]   File "/home/sgautam/.local/lib/python3.10/site-packages/urllib3/util/retry.py", line 592, in increment
[13/07/2023 14:51:45]     raise MaxRetryError(_pool, url, error or ResponseError(cause))
[13/07/2023 14:51:45] urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='localhost', port=8888): Max retries exceeded with url: /druid/v2/sql (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7fed082ffc10>: Failed to establish a new connection: [Errno 111] Connection refused'))
[13/07/2023 14:51:45] 
[13/07/2023 14:51:45] During handling of the above exception, another exception occurred:
[13/07/2023 14:51:45] 
[13/07/2023 14:51:45] Traceback (most recent call last):
[13/07/2023 14:51:45]   File "/mnt/c/Users/winga/OneDrive/Desktop/repos/KDL_SRIP23/data_ingestion/fetch_rows.py", line 10, in <module>
[13/07/2023 14:51:45]     df = pydruid_helper.ExecuteSQLQuery(druid_query)
[13/07/2023 14:51:45]   File "/mnt/c/Users/winga/OneDrive/Desktop/repos/KDL_SRIP23/data_ingestion/pydruid_helper.py", line 8, in ExecuteSQLQuery
[13/07/2023 14:51:45]     json_data = requests.post(druid_url, json={"query": query}).json()
[13/07/2023 14:51:45]   File "/home/sgautam/.local/lib/python3.10/site-packages/requests/api.py", line 115, in post
[13/07/2023 14:51:45]     return request("post", url, data=data, json=json, **kwargs)
[13/07/2023 14:51:45]   File "/home/sgautam/.local/lib/python3.10/site-packages/requests/api.py", line 59, in request
[13/07/2023 14:51:45]     return session.request(method=method, url=url, **kwargs)
[13/07/2023 14:51:45]   File "/home/sgautam/.local/lib/python3.10/site-packages/requests/sessions.py", line 589, in request
[13/07/2023 14:51:45]     resp = self.send(prep, **send_kwargs)
[13/07/2023 14:51:45]   File "/home/sgautam/.local/lib/python3.10/site-packages/requests/sessions.py", line 703, in send
[13/07/2023 14:51:45]     r = adapter.send(request, **kwargs)
[13/07/2023 14:51:45]   File "/home/sgautam/.local/lib/python3.10/site-packages/requests/adapters.py", line 519, in send
[13/07/2023 14:51:45]     raise ConnectionError(e, request=request)
[13/07/2023 14:51:45] requests.exceptions.ConnectionError: HTTPConnectionPool(host='localhost', port=8888): Max retries exceeded with url: /druid/v2/sql (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7fed082ffc10>: Failed to establish a new connection: [Errno 111] Connection refused'))
[13/07/2023 14:51:45] 
[13/07/2023 14:51:45] ***
[13/07/2023 14:53:56] *** EXCEPTION ***
[13/07/2023 14:53:56] Traceback (most recent call last):
[13/07/2023 14:53:56]   File "/home/sgautam/.local/lib/python3.10/site-packages/urllib3/connection.py", line 174, in _new_conn
[13/07/2023 14:53:56]     conn = connection.create_connection(
[13/07/2023 14:53:56]   File "/home/sgautam/.local/lib/python3.10/site-packages/urllib3/util/connection.py", line 95, in create_connection
[13/07/2023 14:53:56]     raise err
[13/07/2023 14:53:56]   File "/home/sgautam/.local/lib/python3.10/site-packages/urllib3/util/connection.py", line 85, in create_connection
[13/07/2023 14:53:56]     sock.connect(sa)
[13/07/2023 14:53:56] ConnectionRefusedError: [Errno 111] Connection refused
[13/07/2023 14:53:56] 
[13/07/2023 14:53:56] During handling of the above exception, another exception occurred:
[13/07/2023 14:53:56] 
[13/07/2023 14:53:56] Traceback (most recent call last):
[13/07/2023 14:53:56]   File "/home/sgautam/.local/lib/python3.10/site-packages/urllib3/connectionpool.py", line 714, in urlopen
[13/07/2023 14:53:56]     httplib_response = self._make_request(
[13/07/2023 14:53:56]   File "/home/sgautam/.local/lib/python3.10/site-packages/urllib3/connectionpool.py", line 415, in _make_request
[13/07/2023 14:53:56]     conn.request(method, url, **httplib_request_kw)
[13/07/2023 14:53:56]   File "/home/sgautam/.local/lib/python3.10/site-packages/urllib3/connection.py", line 244, in request
[13/07/2023 14:53:56]     super(HTTPConnection, self).request(method, url, body=body, headers=headers)
[13/07/2023 14:53:56]   File "/usr/lib/python3.10/http/client.py", line 1282, in request
[13/07/2023 14:53:56]     self._send_request(method, url, body, headers, encode_chunked)
[13/07/2023 14:53:56]   File "/usr/lib/python3.10/http/client.py", line 1328, in _send_request
[13/07/2023 14:53:56]     self.endheaders(body, encode_chunked=encode_chunked)
[13/07/2023 14:53:56]   File "/usr/lib/python3.10/http/client.py", line 1277, in endheaders
[13/07/2023 14:53:56]     self._send_output(message_body, encode_chunked=encode_chunked)
[13/07/2023 14:53:56]   File "/usr/lib/python3.10/http/client.py", line 1037, in _send_output
[13/07/2023 14:53:56]     self.send(msg)
[13/07/2023 14:53:56]   File "/usr/lib/python3.10/http/client.py", line 975, in send
[13/07/2023 14:53:56]     self.connect()
[13/07/2023 14:53:56]   File "/home/sgautam/.local/lib/python3.10/site-packages/urllib3/connection.py", line 205, in connect
[13/07/2023 14:53:56]     conn = self._new_conn()
[13/07/2023 14:53:56]   File "/home/sgautam/.local/lib/python3.10/site-packages/urllib3/connection.py", line 186, in _new_conn
[13/07/2023 14:53:56]     raise NewConnectionError(
[13/07/2023 14:53:56] urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x7f69f06bfc10>: Failed to establish a new connection: [Errno 111] Connection refused
[13/07/2023 14:53:56] 
[13/07/2023 14:53:56] During handling of the above exception, another exception occurred:
[13/07/2023 14:53:56] 
[13/07/2023 14:53:56] Traceback (most recent call last):
[13/07/2023 14:53:56]   File "/home/sgautam/.local/lib/python3.10/site-packages/requests/adapters.py", line 486, in send
[13/07/2023 14:53:56]     resp = conn.urlopen(
[13/07/2023 14:53:56]   File "/home/sgautam/.local/lib/python3.10/site-packages/urllib3/connectionpool.py", line 798, in urlopen
[13/07/2023 14:53:56]     retries = retries.increment(
[13/07/2023 14:53:56]   File "/home/sgautam/.local/lib/python3.10/site-packages/urllib3/util/retry.py", line 592, in increment
[13/07/2023 14:53:56]     raise MaxRetryError(_pool, url, error or ResponseError(cause))
[13/07/2023 14:53:56] urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='localhost', port=8888): Max retries exceeded with url: /druid/v2/sql (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f69f06bfc10>: Failed to establish a new connection: [Errno 111] Connection refused'))
[13/07/2023 14:53:56] 
[13/07/2023 14:53:56] During handling of the above exception, another exception occurred:
[13/07/2023 14:53:56] 
[13/07/2023 14:53:56] Traceback (most recent call last):
[13/07/2023 14:53:56]   File "/mnt/c/Users/winga/OneDrive/Desktop/repos/KDL_SRIP23/data_ingestion/fetch_rows.py", line 10, in <module>
[13/07/2023 14:53:56]     df = pydruid_helper.ExecuteSQLQuery(druid_query)
[13/07/2023 14:53:56]   File "/mnt/c/Users/winga/OneDrive/Desktop/repos/KDL_SRIP23/data_ingestion/pydruid_helper.py", line 8, in ExecuteSQLQuery
[13/07/2023 14:53:56]     json_data = requests.post(druid_url, json={"query": query}).json()
[13/07/2023 14:53:56]   File "/home/sgautam/.local/lib/python3.10/site-packages/requests/api.py", line 115, in post
[13/07/2023 14:53:56]     return request("post", url, data=data, json=json, **kwargs)
[13/07/2023 14:53:56]   File "/home/sgautam/.local/lib/python3.10/site-packages/requests/api.py", line 59, in request
[13/07/2023 14:53:56]     return session.request(method=method, url=url, **kwargs)
[13/07/2023 14:53:56]   File "/home/sgautam/.local/lib/python3.10/site-packages/requests/sessions.py", line 589, in request
[13/07/2023 14:53:56]     resp = self.send(prep, **send_kwargs)
[13/07/2023 14:53:56]   File "/home/sgautam/.local/lib/python3.10/site-packages/requests/sessions.py", line 703, in send
[13/07/2023 14:53:56]     r = adapter.send(request, **kwargs)
[13/07/2023 14:53:56]   File "/home/sgautam/.local/lib/python3.10/site-packages/requests/adapters.py", line 519, in send
[13/07/2023 14:53:56]     raise ConnectionError(e, request=request)
[13/07/2023 14:53:56] requests.exceptions.ConnectionError: HTTPConnectionPool(host='localhost', port=8888): Max retries exceeded with url: /druid/v2/sql (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f69f06bfc10>: Failed to establish a new connection: [Errno 111] Connection refused'))
[13/07/2023 14:53:56] 
[13/07/2023 14:53:56] ***
[13/07/2023 16:25:46] Converted sheet 1689245741_SDG1-4 Indicatorwise Results (1).SDG 1- Taluka data to 1689245741_SDG1-4 Indicatorwise Results (1)_SDG 1- Taluka data.csv
[13/07/2023 16:25:46] Converted sheet 1689245741_SDG1-4 Indicatorwise Results (1).SDG 1 -Gp level data to 1689245741_SDG1-4 Indicatorwise Results (1)_SDG 1 -Gp level data.csv
[13/07/2023 16:25:46] Converted sheet 1689245741_SDG1-4 Indicatorwise Results (1).SDG 2 Malnutrition Taluka to 1689245741_SDG1-4 Indicatorwise Results (1)_SDG 2 Malnutrition Taluka.csv
[13/07/2023 16:25:46] Converted sheet 1689245741_SDG1-4 Indicatorwise Results (1).SDG2 Gp data to 1689245741_SDG1-4 Indicatorwise Results (1)_SDG2 Gp data.csv
[13/07/2023 16:25:46] Converted sheet 1689245741_SDG1-4 Indicatorwise Results (1).SDG 3 Taluka Data to 1689245741_SDG1-4 Indicatorwise Results (1)_SDG 3 Taluka Data.csv
[13/07/2023 16:25:46] Converted sheet 1689245741_SDG1-4 Indicatorwise Results (1).SDG 4 Taluka to 1689245741_SDG1-4 Indicatorwise Results (1)_SDG 4 Taluka.csv
[13/07/2023 16:25:47] Converted sheet 1689245741_SDG1-4 Indicatorwise Results (1).SDG4 Gp level data to 1689245741_SDG1-4 Indicatorwise Results (1)_SDG4 Gp level data.csv
[13/07/2023 16:25:47] Uploading file: 1689245741_SDG1-4 Indicatorwise Results (1).xlsx
[13/07/2023 16:25:47] Writing metadata for 1689245741_SDG1-4 Indicatorwise Results (1)_SDG 1- Taluka data.csv.
[13/07/2023 16:25:47] Creating JSON spec for 1689245741_SDG1-4 Indicatorwise Results (1)_SDG 1- Taluka data.csv in datasets/1689245741_SDG1-4 Indicatorwise Results (1)_SDG 1- Taluka data.csv.json
[13/07/2023 16:25:47] Druid Task Succeeded.
[13/07/2023 16:25:47] Writing metadata for 1689245741_SDG1-4 Indicatorwise Results (1)_SDG 1 -Gp level data.csv.
[13/07/2023 16:25:47] Creating JSON spec for 1689245741_SDG1-4 Indicatorwise Results (1)_SDG 1 -Gp level data.csv in datasets/1689245741_SDG1-4 Indicatorwise Results (1)_SDG 1 -Gp level data.csv.json
[13/07/2023 16:25:47] Druid Task Succeeded.
[13/07/2023 16:25:47] Writing metadata for 1689245741_SDG1-4 Indicatorwise Results (1)_SDG 2 Malnutrition Taluka.csv.
[13/07/2023 16:25:47] Creating JSON spec for 1689245741_SDG1-4 Indicatorwise Results (1)_SDG 2 Malnutrition Taluka.csv in datasets/1689245741_SDG1-4 Indicatorwise Results (1)_SDG 2 Malnutrition Taluka.csv.json
[13/07/2023 16:25:47] Druid Task Succeeded.
[13/07/2023 16:25:47] Writing metadata for 1689245741_SDG1-4 Indicatorwise Results (1)_SDG2 Gp data.csv.
[13/07/2023 16:25:47] Creating JSON spec for 1689245741_SDG1-4 Indicatorwise Results (1)_SDG2 Gp data.csv in datasets/1689245741_SDG1-4 Indicatorwise Results (1)_SDG2 Gp data.csv.json
[13/07/2023 16:25:47] Druid Task Succeeded.
[13/07/2023 16:25:47] Writing metadata for 1689245741_SDG1-4 Indicatorwise Results (1)_SDG 3 Taluka Data.csv.
[13/07/2023 16:25:47] Creating JSON spec for 1689245741_SDG1-4 Indicatorwise Results (1)_SDG 3 Taluka Data.csv in datasets/1689245741_SDG1-4 Indicatorwise Results (1)_SDG 3 Taluka Data.csv.json
[13/07/2023 16:25:47] Druid Task Succeeded.
[13/07/2023 16:25:47] Writing metadata for 1689245741_SDG1-4 Indicatorwise Results (1)_SDG 4 Taluka.csv.
[13/07/2023 16:25:48] Creating JSON spec for 1689245741_SDG1-4 Indicatorwise Results (1)_SDG 4 Taluka.csv in datasets/1689245741_SDG1-4 Indicatorwise Results (1)_SDG 4 Taluka.csv.json
[13/07/2023 16:25:48] Druid Task Succeeded.
[13/07/2023 16:25:48] Writing metadata for 1689245741_SDG1-4 Indicatorwise Results (1)_SDG4 Gp level data.csv.
[13/07/2023 16:25:48] Creating JSON spec for 1689245741_SDG1-4 Indicatorwise Results (1)_SDG4 Gp level data.csv in datasets/1689245741_SDG1-4 Indicatorwise Results (1)_SDG4 Gp level data.csv.json
[13/07/2023 16:25:48] Druid Task Succeeded.
[13/07/2023 16:34:37] Uploading file: 1689246277_SDG_1_Taluka_Data.csv
[13/07/2023 16:34:37] Writing metadata for 1689246277_SDG_1_Taluka_Data.csv.
[13/07/2023 16:34:37] Creating JSON spec for 1689246277_SDG_1_Taluka_Data.csv in datasets/1689246277_SDG_1_Taluka_Data.csv.json
[13/07/2023 16:34:37] Druid Task Succeeded.
[13/07/2023 16:39:46] Uploading file: 1689246585_SDG1_Gp_Level_Data.csv
[13/07/2023 16:39:46] Writing metadata for 1689246585_SDG1_Gp_Level_Data.csv.
[13/07/2023 16:39:46] Creating JSON spec for 1689246585_SDG1_Gp_Level_Data.csv in datasets/1689246585_SDG1_Gp_Level_Data.csv.json
[13/07/2023 16:39:46] Druid Task Succeeded.
[13/07/2023 16:56:12] Uploading file: 1689247572_SDG4_Taluka_Data.csv
[13/07/2023 16:56:12] Writing metadata for 1689247572_SDG4_Taluka_Data.csv.
[13/07/2023 16:56:12] Creating JSON spec for 1689247572_SDG4_Taluka_Data.csv in datasets/1689247572_SDG4_Taluka_Data.csv.json
[13/07/2023 16:56:12] Druid Task Succeeded.
[13/07/2023 16:56:42] Uploading file: 1689247601_SDG4_Gp_Level_Data.csv
[13/07/2023 16:56:42] Writing metadata for 1689247601_SDG4_Gp_Level_Data.csv.
[13/07/2023 16:56:42] Creating JSON spec for 1689247601_SDG4_Gp_Level_Data.csv in datasets/1689247601_SDG4_Gp_Level_Data.csv.json
[13/07/2023 16:56:42] Druid Task Succeeded.
[13/07/2023 17:02:28] Uploading file: 1689247948_SDG4_Gp_Level_Data.csv
[13/07/2023 17:02:28] Writing metadata for 1689247948_SDG4_Gp_Level_Data.csv.
[13/07/2023 17:02:28] Creating JSON spec for 1689247948_SDG4_Gp_Level_Data.csv in datasets/1689247948_SDG4_Gp_Level_Data.csv.json
[13/07/2023 17:02:28] Druid Task Succeeded.
[13/07/2023 17:12:15] Uploading file: 1689248534_SDG4_Gp_Level_Data.csv
[13/07/2023 17:12:15] Writing metadata for 1689248534_SDG4_Gp_Level_Data.csv.
[13/07/2023 17:12:15] *** EXCEPTION ***
[13/07/2023 17:12:15] Traceback (most recent call last):
[13/07/2023 17:12:15]   File "/mnt/c/Users/winga/OneDrive/Desktop/repos/KDL_SRIP23/data_ingestion/metadata_writer.py", line 15, in WriteMetaData
[13/07/2023 17:12:15]     df = pandas.read_csv(path + "/" + uploaded_file + ".csv")
[13/07/2023 17:12:15]   File "/home/sgautam/.local/lib/python3.10/site-packages/pandas/io/parsers/readers.py", line 912, in read_csv
[13/07/2023 17:12:15]     return _read(filepath_or_buffer, kwds)
[13/07/2023 17:12:15]   File "/home/sgautam/.local/lib/python3.10/site-packages/pandas/io/parsers/readers.py", line 583, in _read
[13/07/2023 17:12:15]     return parser.read(nrows)
[13/07/2023 17:12:15]   File "/home/sgautam/.local/lib/python3.10/site-packages/pandas/io/parsers/readers.py", line 1704, in read
[13/07/2023 17:12:15]     ) = self._engine.read(  # type: ignore[attr-defined]
[13/07/2023 17:12:15]   File "/home/sgautam/.local/lib/python3.10/site-packages/pandas/io/parsers/c_parser_wrapper.py", line 234, in read
[13/07/2023 17:12:15]     chunks = self._reader.read_low_memory(nrows)
[13/07/2023 17:12:15]   File "pandas/_libs/parsers.pyx", line 814, in pandas._libs.parsers.TextReader.read_low_memory
[13/07/2023 17:12:15]   File "pandas/_libs/parsers.pyx", line 875, in pandas._libs.parsers.TextReader._read_rows
[13/07/2023 17:12:15]   File "pandas/_libs/parsers.pyx", line 850, in pandas._libs.parsers.TextReader._tokenize_rows
[13/07/2023 17:12:15]   File "pandas/_libs/parsers.pyx", line 861, in pandas._libs.parsers.TextReader._check_tokenize_status
[13/07/2023 17:12:15]   File "pandas/_libs/parsers.pyx", line 2029, in pandas._libs.parsers.raise_parser_error
[13/07/2023 17:12:15] pandas.errors.ParserError: Error tokenizing data. C error: Expected 74 fields in line 1309, saw 75
[13/07/2023 17:12:15] 
[13/07/2023 17:12:15] 
[13/07/2023 17:12:15] ***
[13/07/2023 17:12:15] *** EXCEPTION ***
[13/07/2023 17:12:15] Traceback (most recent call last):
[13/07/2023 17:12:15]   File "/mnt/c/Users/winga/OneDrive/Desktop/repos/KDL_SRIP23/data_ingestion/upload_single_druid.py", line 20, in <module>
[13/07/2023 17:12:15]     json_object = get_druid_json(file, os.getcwd() + "/" + settings.DATASETS_DIR, settings.DATASETS_DIR + "/" + file + ".json")
[13/07/2023 17:12:15]   File "/mnt/c/Users/winga/OneDrive/Desktop/repos/KDL_SRIP23/data_ingestion/druid_lib.py", line 23, in get_druid_json
[13/07/2023 17:12:15]     df = pd.read_csv(file_path + "/" + file_name)
[13/07/2023 17:12:15]   File "/home/sgautam/.local/lib/python3.10/site-packages/pandas/io/parsers/readers.py", line 912, in read_csv
[13/07/2023 17:12:15]     return _read(filepath_or_buffer, kwds)
[13/07/2023 17:12:15]   File "/home/sgautam/.local/lib/python3.10/site-packages/pandas/io/parsers/readers.py", line 583, in _read
[13/07/2023 17:12:15]     return parser.read(nrows)
[13/07/2023 17:12:15]   File "/home/sgautam/.local/lib/python3.10/site-packages/pandas/io/parsers/readers.py", line 1704, in read
[13/07/2023 17:12:15]     ) = self._engine.read(  # type: ignore[attr-defined]
[13/07/2023 17:12:15]   File "/home/sgautam/.local/lib/python3.10/site-packages/pandas/io/parsers/c_parser_wrapper.py", line 234, in read
[13/07/2023 17:12:15]     chunks = self._reader.read_low_memory(nrows)
[13/07/2023 17:12:15]   File "pandas/_libs/parsers.pyx", line 814, in pandas._libs.parsers.TextReader.read_low_memory
[13/07/2023 17:12:15]   File "pandas/_libs/parsers.pyx", line 875, in pandas._libs.parsers.TextReader._read_rows
[13/07/2023 17:12:15]   File "pandas/_libs/parsers.pyx", line 850, in pandas._libs.parsers.TextReader._tokenize_rows
[13/07/2023 17:12:15]   File "pandas/_libs/parsers.pyx", line 861, in pandas._libs.parsers.TextReader._check_tokenize_status
[13/07/2023 17:12:15]   File "pandas/_libs/parsers.pyx", line 2029, in pandas._libs.parsers.raise_parser_error
[13/07/2023 17:12:15] pandas.errors.ParserError: Error tokenizing data. C error: Expected 74 fields in line 1309, saw 75
[13/07/2023 17:12:15] 
[13/07/2023 17:12:15] 
[13/07/2023 17:12:15] ***
[13/07/2023 17:13:25] Uploading file: 1689248605_SDG4_Gp_Level_Data.csv
[13/07/2023 17:13:25] Writing metadata for 1689248605_SDG4_Gp_Level_Data.csv.
[13/07/2023 17:13:25] *** EXCEPTION ***
[13/07/2023 17:13:25] Traceback (most recent call last):
[13/07/2023 17:13:25]   File "/mnt/c/Users/winga/OneDrive/Desktop/repos/KDL_SRIP23/data_ingestion/metadata_writer.py", line 15, in WriteMetaData
[13/07/2023 17:13:25]     df = pandas.read_csv(path + "/" + uploaded_file + ".csv")
[13/07/2023 17:13:25]   File "/home/sgautam/.local/lib/python3.10/site-packages/pandas/io/parsers/readers.py", line 912, in read_csv
[13/07/2023 17:13:25]     return _read(filepath_or_buffer, kwds)
[13/07/2023 17:13:25]   File "/home/sgautam/.local/lib/python3.10/site-packages/pandas/io/parsers/readers.py", line 583, in _read
[13/07/2023 17:13:25]     return parser.read(nrows)
[13/07/2023 17:13:25]   File "/home/sgautam/.local/lib/python3.10/site-packages/pandas/io/parsers/readers.py", line 1704, in read
[13/07/2023 17:13:25]     ) = self._engine.read(  # type: ignore[attr-defined]
[13/07/2023 17:13:25]   File "/home/sgautam/.local/lib/python3.10/site-packages/pandas/io/parsers/c_parser_wrapper.py", line 234, in read
[13/07/2023 17:13:25]     chunks = self._reader.read_low_memory(nrows)
[13/07/2023 17:13:25]   File "pandas/_libs/parsers.pyx", line 814, in pandas._libs.parsers.TextReader.read_low_memory
[13/07/2023 17:13:25]   File "pandas/_libs/parsers.pyx", line 875, in pandas._libs.parsers.TextReader._read_rows
[13/07/2023 17:13:25]   File "pandas/_libs/parsers.pyx", line 850, in pandas._libs.parsers.TextReader._tokenize_rows
[13/07/2023 17:13:25]   File "pandas/_libs/parsers.pyx", line 861, in pandas._libs.parsers.TextReader._check_tokenize_status
[13/07/2023 17:13:25]   File "pandas/_libs/parsers.pyx", line 2029, in pandas._libs.parsers.raise_parser_error
[13/07/2023 17:13:25] pandas.errors.ParserError: Error tokenizing data. C error: Expected 74 fields in line 1309, saw 75
[13/07/2023 17:13:25] 
[13/07/2023 17:13:25] 
[13/07/2023 17:13:25] ***
[13/07/2023 17:13:25] *** EXCEPTION ***
[13/07/2023 17:13:25] Traceback (most recent call last):
[13/07/2023 17:13:25]   File "/mnt/c/Users/winga/OneDrive/Desktop/repos/KDL_SRIP23/data_ingestion/upload_single_druid.py", line 20, in <module>
[13/07/2023 17:13:25]     json_object = get_druid_json(file, os.getcwd() + "/" + settings.DATASETS_DIR, settings.DATASETS_DIR + "/" + file + ".json")
[13/07/2023 17:13:25]   File "/mnt/c/Users/winga/OneDrive/Desktop/repos/KDL_SRIP23/data_ingestion/druid_lib.py", line 23, in get_druid_json
[13/07/2023 17:13:25]     df = pd.read_csv(file_path + "/" + file_name)
[13/07/2023 17:13:25]   File "/home/sgautam/.local/lib/python3.10/site-packages/pandas/io/parsers/readers.py", line 912, in read_csv
[13/07/2023 17:13:25]     return _read(filepath_or_buffer, kwds)
[13/07/2023 17:13:25]   File "/home/sgautam/.local/lib/python3.10/site-packages/pandas/io/parsers/readers.py", line 583, in _read
[13/07/2023 17:13:25]     return parser.read(nrows)
[13/07/2023 17:13:25]   File "/home/sgautam/.local/lib/python3.10/site-packages/pandas/io/parsers/readers.py", line 1704, in read
[13/07/2023 17:13:25]     ) = self._engine.read(  # type: ignore[attr-defined]
[13/07/2023 17:13:25]   File "/home/sgautam/.local/lib/python3.10/site-packages/pandas/io/parsers/c_parser_wrapper.py", line 234, in read
[13/07/2023 17:13:25]     chunks = self._reader.read_low_memory(nrows)
[13/07/2023 17:13:25]   File "pandas/_libs/parsers.pyx", line 814, in pandas._libs.parsers.TextReader.read_low_memory
[13/07/2023 17:13:25]   File "pandas/_libs/parsers.pyx", line 875, in pandas._libs.parsers.TextReader._read_rows
[13/07/2023 17:13:25]   File "pandas/_libs/parsers.pyx", line 850, in pandas._libs.parsers.TextReader._tokenize_rows
[13/07/2023 17:13:25]   File "pandas/_libs/parsers.pyx", line 861, in pandas._libs.parsers.TextReader._check_tokenize_status
[13/07/2023 17:13:25]   File "pandas/_libs/parsers.pyx", line 2029, in pandas._libs.parsers.raise_parser_error
[13/07/2023 17:13:25] pandas.errors.ParserError: Error tokenizing data. C error: Expected 74 fields in line 1309, saw 75
[13/07/2023 17:13:25] 
[13/07/2023 17:13:25] 
[13/07/2023 17:13:25] ***
[13/07/2023 17:18:56] Uploading file: 1689248935_SDG4_Gp_Level_Data.csv
[13/07/2023 17:18:56] Writing metadata for 1689248935_SDG4_Gp_Level_Data.csv.
[13/07/2023 17:18:56] Creating JSON spec for 1689248935_SDG4_Gp_Level_Data.csv in datasets/1689248935_SDG4_Gp_Level_Data.csv.json
[13/07/2023 17:18:56] Druid Task Succeeded.
[13/07/2023 18:28:16] Uploading file: 1689253096_SDG4_Gp_Level_Data.csv
[13/07/2023 18:28:16] Writing metadata for 1689253096_SDG4_Gp_Level_Data.csv.
[13/07/2023 18:28:16] Creating JSON spec for 1689253096_SDG4_Gp_Level_Data.csv in datasets/1689253096_SDG4_Gp_Level_Data.csv.json
[13/07/2023 18:28:17] Druid Task Succeeded.
[13/07/2023 18:42:05] Uploading file: 1689253925_SDG4_Gp_Level_Data_Cleaned.csv
[13/07/2023 18:42:05] Writing metadata for 1689253925_SDG4_Gp_Level_Data_Cleaned.csv.
[13/07/2023 18:42:05] Creating JSON spec for 1689253925_SDG4_Gp_Level_Data_Cleaned.csv in datasets/1689253925_SDG4_Gp_Level_Data_Cleaned.csv.json
[13/07/2023 18:42:05] Druid Task Succeeded.
[15/07/2023 18:49:16] *** EXCEPTION ***
[15/07/2023 18:49:16] Traceback (most recent call last):
[15/07/2023 18:49:16]   File "/home/sgautam/.local/lib/python3.10/site-packages/urllib3/connection.py", line 174, in _new_conn
[15/07/2023 18:49:16]     conn = connection.create_connection(
[15/07/2023 18:49:16]   File "/home/sgautam/.local/lib/python3.10/site-packages/urllib3/util/connection.py", line 95, in create_connection
[15/07/2023 18:49:16]     raise err
[15/07/2023 18:49:16]   File "/home/sgautam/.local/lib/python3.10/site-packages/urllib3/util/connection.py", line 85, in create_connection
[15/07/2023 18:49:16]     sock.connect(sa)
[15/07/2023 18:49:16] ConnectionRefusedError: [Errno 111] Connection refused
[15/07/2023 18:49:16] 
[15/07/2023 18:49:16] During handling of the above exception, another exception occurred:
[15/07/2023 18:49:16] 
[15/07/2023 18:49:16] Traceback (most recent call last):
[15/07/2023 18:49:16]   File "/home/sgautam/.local/lib/python3.10/site-packages/urllib3/connectionpool.py", line 714, in urlopen
[15/07/2023 18:49:16]     httplib_response = self._make_request(
[15/07/2023 18:49:16]   File "/home/sgautam/.local/lib/python3.10/site-packages/urllib3/connectionpool.py", line 415, in _make_request
[15/07/2023 18:49:16]     conn.request(method, url, **httplib_request_kw)
[15/07/2023 18:49:16]   File "/home/sgautam/.local/lib/python3.10/site-packages/urllib3/connection.py", line 244, in request
[15/07/2023 18:49:16]     super(HTTPConnection, self).request(method, url, body=body, headers=headers)
[15/07/2023 18:49:16]   File "/usr/lib/python3.10/http/client.py", line 1282, in request
[15/07/2023 18:49:16]     self._send_request(method, url, body, headers, encode_chunked)
[15/07/2023 18:49:16]   File "/usr/lib/python3.10/http/client.py", line 1328, in _send_request
[15/07/2023 18:49:16]     self.endheaders(body, encode_chunked=encode_chunked)
[15/07/2023 18:49:16]   File "/usr/lib/python3.10/http/client.py", line 1277, in endheaders
[15/07/2023 18:49:16]     self._send_output(message_body, encode_chunked=encode_chunked)
[15/07/2023 18:49:16]   File "/usr/lib/python3.10/http/client.py", line 1037, in _send_output
[15/07/2023 18:49:16]     self.send(msg)
[15/07/2023 18:49:16]   File "/usr/lib/python3.10/http/client.py", line 975, in send
[15/07/2023 18:49:16]     self.connect()
[15/07/2023 18:49:16]   File "/home/sgautam/.local/lib/python3.10/site-packages/urllib3/connection.py", line 205, in connect
[15/07/2023 18:49:16]     conn = self._new_conn()
[15/07/2023 18:49:16]   File "/home/sgautam/.local/lib/python3.10/site-packages/urllib3/connection.py", line 186, in _new_conn
[15/07/2023 18:49:16]     raise NewConnectionError(
[15/07/2023 18:49:16] urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x7fc0e9da02b0>: Failed to establish a new connection: [Errno 111] Connection refused
[15/07/2023 18:49:16] 
[15/07/2023 18:49:16] During handling of the above exception, another exception occurred:
[15/07/2023 18:49:16] 
[15/07/2023 18:49:16] Traceback (most recent call last):
[15/07/2023 18:49:16]   File "/home/sgautam/.local/lib/python3.10/site-packages/requests/adapters.py", line 486, in send
[15/07/2023 18:49:16]     resp = conn.urlopen(
[15/07/2023 18:49:16]   File "/home/sgautam/.local/lib/python3.10/site-packages/urllib3/connectionpool.py", line 798, in urlopen
[15/07/2023 18:49:16]     retries = retries.increment(
[15/07/2023 18:49:16]   File "/home/sgautam/.local/lib/python3.10/site-packages/urllib3/util/retry.py", line 592, in increment
[15/07/2023 18:49:16]     raise MaxRetryError(_pool, url, error or ResponseError(cause))
[15/07/2023 18:49:16] urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='localhost', port=8888): Max retries exceeded with url: /druid/v2/sql (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7fc0e9da02b0>: Failed to establish a new connection: [Errno 111] Connection refused'))
[15/07/2023 18:49:16] 
[15/07/2023 18:49:16] During handling of the above exception, another exception occurred:
[15/07/2023 18:49:16] 
[15/07/2023 18:49:16] Traceback (most recent call last):
[15/07/2023 18:49:16]   File "/mnt/c/Users/winga/OneDrive/Desktop/repos/KDL_SRIP23/data_ingestion/csv_from_druid.py", line 12, in <module>
[15/07/2023 18:49:16]     result = pydruid_helper.ExecuteSQLQueryGetCSV(sys.argv[1])
[15/07/2023 18:49:16]   File "/mnt/c/Users/winga/OneDrive/Desktop/repos/KDL_SRIP23/data_ingestion/pydruid_helper.py", line 17, in ExecuteSQLQueryGetCSV
[15/07/2023 18:49:16]     csv = requests.post(druid_url, json={"query": query, "resultFormat": "csv", "header": True}).text
[15/07/2023 18:49:16]   File "/home/sgautam/.local/lib/python3.10/site-packages/requests/api.py", line 115, in post
[15/07/2023 18:49:16]     return request("post", url, data=data, json=json, **kwargs)
[15/07/2023 18:49:16]   File "/home/sgautam/.local/lib/python3.10/site-packages/requests/api.py", line 59, in request
[15/07/2023 18:49:16]     return session.request(method=method, url=url, **kwargs)
[15/07/2023 18:49:16]   File "/home/sgautam/.local/lib/python3.10/site-packages/requests/sessions.py", line 589, in request
[15/07/2023 18:49:16]     resp = self.send(prep, **send_kwargs)
[15/07/2023 18:49:16]   File "/home/sgautam/.local/lib/python3.10/site-packages/requests/sessions.py", line 703, in send
[15/07/2023 18:49:16]     r = adapter.send(request, **kwargs)
[15/07/2023 18:49:16]   File "/home/sgautam/.local/lib/python3.10/site-packages/requests/adapters.py", line 519, in send
[15/07/2023 18:49:16]     raise ConnectionError(e, request=request)
[15/07/2023 18:49:16] requests.exceptions.ConnectionError: HTTPConnectionPool(host='localhost', port=8888): Max retries exceeded with url: /druid/v2/sql (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7fc0e9da02b0>: Failed to establish a new connection: [Errno 111] Connection refused'))
[15/07/2023 18:49:16] 
[15/07/2023 18:49:16] ***
[15/07/2023 18:53:24] *** EXCEPTION ***
[15/07/2023 18:53:24] Traceback (most recent call last):
[15/07/2023 18:53:24]   File "/home/sgautam/.local/lib/python3.10/site-packages/urllib3/connection.py", line 174, in _new_conn
[15/07/2023 18:53:24]     conn = connection.create_connection(
[15/07/2023 18:53:24]   File "/home/sgautam/.local/lib/python3.10/site-packages/urllib3/util/connection.py", line 95, in create_connection
[15/07/2023 18:53:24]     raise err
[15/07/2023 18:53:24]   File "/home/sgautam/.local/lib/python3.10/site-packages/urllib3/util/connection.py", line 85, in create_connection
[15/07/2023 18:53:24]     sock.connect(sa)
[15/07/2023 18:53:24] ConnectionRefusedError: [Errno 111] Connection refused
[15/07/2023 18:53:24] 
[15/07/2023 18:53:24] During handling of the above exception, another exception occurred:
[15/07/2023 18:53:24] 
[15/07/2023 18:53:24] Traceback (most recent call last):
[15/07/2023 18:53:24]   File "/home/sgautam/.local/lib/python3.10/site-packages/urllib3/connectionpool.py", line 714, in urlopen
[15/07/2023 18:53:24]     httplib_response = self._make_request(
[15/07/2023 18:53:24]   File "/home/sgautam/.local/lib/python3.10/site-packages/urllib3/connectionpool.py", line 415, in _make_request
[15/07/2023 18:53:24]     conn.request(method, url, **httplib_request_kw)
[15/07/2023 18:53:24]   File "/home/sgautam/.local/lib/python3.10/site-packages/urllib3/connection.py", line 244, in request
[15/07/2023 18:53:24]     super(HTTPConnection, self).request(method, url, body=body, headers=headers)
[15/07/2023 18:53:24]   File "/usr/lib/python3.10/http/client.py", line 1282, in request
[15/07/2023 18:53:24]     self._send_request(method, url, body, headers, encode_chunked)
[15/07/2023 18:53:24]   File "/usr/lib/python3.10/http/client.py", line 1328, in _send_request
[15/07/2023 18:53:24]     self.endheaders(body, encode_chunked=encode_chunked)
[15/07/2023 18:53:24]   File "/usr/lib/python3.10/http/client.py", line 1277, in endheaders
[15/07/2023 18:53:24]     self._send_output(message_body, encode_chunked=encode_chunked)
[15/07/2023 18:53:24]   File "/usr/lib/python3.10/http/client.py", line 1037, in _send_output
[15/07/2023 18:53:24]     self.send(msg)
[15/07/2023 18:53:24]   File "/usr/lib/python3.10/http/client.py", line 975, in send
[15/07/2023 18:53:24]     self.connect()
[15/07/2023 18:53:24]   File "/home/sgautam/.local/lib/python3.10/site-packages/urllib3/connection.py", line 205, in connect
[15/07/2023 18:53:24]     conn = self._new_conn()
[15/07/2023 18:53:24]   File "/home/sgautam/.local/lib/python3.10/site-packages/urllib3/connection.py", line 186, in _new_conn
[15/07/2023 18:53:24]     raise NewConnectionError(
[15/07/2023 18:53:24] urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x7f0b64d9c430>: Failed to establish a new connection: [Errno 111] Connection refused
[15/07/2023 18:53:24] 
[15/07/2023 18:53:24] During handling of the above exception, another exception occurred:
[15/07/2023 18:53:24] 
[15/07/2023 18:53:24] Traceback (most recent call last):
[15/07/2023 18:53:24]   File "/home/sgautam/.local/lib/python3.10/site-packages/requests/adapters.py", line 486, in send
[15/07/2023 18:53:24]     resp = conn.urlopen(
[15/07/2023 18:53:24]   File "/home/sgautam/.local/lib/python3.10/site-packages/urllib3/connectionpool.py", line 798, in urlopen
[15/07/2023 18:53:24]     retries = retries.increment(
[15/07/2023 18:53:24]   File "/home/sgautam/.local/lib/python3.10/site-packages/urllib3/util/retry.py", line 592, in increment
[15/07/2023 18:53:24]     raise MaxRetryError(_pool, url, error or ResponseError(cause))
[15/07/2023 18:53:24] urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='localhost', port=8888): Max retries exceeded with url: /druid/v2/sql (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f0b64d9c430>: Failed to establish a new connection: [Errno 111] Connection refused'))
[15/07/2023 18:53:24] 
[15/07/2023 18:53:24] During handling of the above exception, another exception occurred:
[15/07/2023 18:53:24] 
[15/07/2023 18:53:24] Traceback (most recent call last):
[15/07/2023 18:53:24]   File "/mnt/c/Users/winga/OneDrive/Desktop/repos/KDL_SRIP23/data_ingestion/csv_from_druid.py", line 13, in <module>
[15/07/2023 18:53:24]     result = pydruid_helper.ExecuteSQLQueryGetCSV(sys.argv[1])
[15/07/2023 18:53:24]   File "/mnt/c/Users/winga/OneDrive/Desktop/repos/KDL_SRIP23/data_ingestion/pydruid_helper.py", line 17, in ExecuteSQLQueryGetCSV
[15/07/2023 18:53:24]     csv = requests.post(druid_url, json={"query": query, "resultFormat": "csv", "header": True}).text
[15/07/2023 18:53:24]   File "/home/sgautam/.local/lib/python3.10/site-packages/requests/api.py", line 115, in post
[15/07/2023 18:53:24]     return request("post", url, data=data, json=json, **kwargs)
[15/07/2023 18:53:24]   File "/home/sgautam/.local/lib/python3.10/site-packages/requests/api.py", line 59, in request
[15/07/2023 18:53:24]     return session.request(method=method, url=url, **kwargs)
[15/07/2023 18:53:24]   File "/home/sgautam/.local/lib/python3.10/site-packages/requests/sessions.py", line 589, in request
[15/07/2023 18:53:24]     resp = self.send(prep, **send_kwargs)
[15/07/2023 18:53:24]   File "/home/sgautam/.local/lib/python3.10/site-packages/requests/sessions.py", line 703, in send
[15/07/2023 18:53:24]     r = adapter.send(request, **kwargs)
[15/07/2023 18:53:24]   File "/home/sgautam/.local/lib/python3.10/site-packages/requests/adapters.py", line 519, in send
[15/07/2023 18:53:24]     raise ConnectionError(e, request=request)
[15/07/2023 18:53:24] requests.exceptions.ConnectionError: HTTPConnectionPool(host='localhost', port=8888): Max retries exceeded with url: /druid/v2/sql (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f0b64d9c430>: Failed to establish a new connection: [Errno 111] Connection refused'))
[15/07/2023 18:53:24] 
[15/07/2023 18:53:24] ***
[15/07/2023 18:54:11] *** EXCEPTION ***
[15/07/2023 18:54:11] Traceback (most recent call last):
[15/07/2023 18:54:11]   File "/home/sgautam/.local/lib/python3.10/site-packages/urllib3/connection.py", line 174, in _new_conn
[15/07/2023 18:54:11]     conn = connection.create_connection(
[15/07/2023 18:54:11]   File "/home/sgautam/.local/lib/python3.10/site-packages/urllib3/util/connection.py", line 95, in create_connection
[15/07/2023 18:54:11]     raise err
[15/07/2023 18:54:11]   File "/home/sgautam/.local/lib/python3.10/site-packages/urllib3/util/connection.py", line 85, in create_connection
[15/07/2023 18:54:11]     sock.connect(sa)
[15/07/2023 18:54:11] ConnectionRefusedError: [Errno 111] Connection refused
[15/07/2023 18:54:11] 
[15/07/2023 18:54:11] During handling of the above exception, another exception occurred:
[15/07/2023 18:54:11] 
[15/07/2023 18:54:11] Traceback (most recent call last):
[15/07/2023 18:54:11]   File "/home/sgautam/.local/lib/python3.10/site-packages/urllib3/connectionpool.py", line 714, in urlopen
[15/07/2023 18:54:11]     httplib_response = self._make_request(
[15/07/2023 18:54:11]   File "/home/sgautam/.local/lib/python3.10/site-packages/urllib3/connectionpool.py", line 415, in _make_request
[15/07/2023 18:54:11]     conn.request(method, url, **httplib_request_kw)
[15/07/2023 18:54:11]   File "/home/sgautam/.local/lib/python3.10/site-packages/urllib3/connection.py", line 244, in request
[15/07/2023 18:54:11]     super(HTTPConnection, self).request(method, url, body=body, headers=headers)
[15/07/2023 18:54:11]   File "/usr/lib/python3.10/http/client.py", line 1282, in request
[15/07/2023 18:54:11]     self._send_request(method, url, body, headers, encode_chunked)
[15/07/2023 18:54:11]   File "/usr/lib/python3.10/http/client.py", line 1328, in _send_request
[15/07/2023 18:54:11]     self.endheaders(body, encode_chunked=encode_chunked)
[15/07/2023 18:54:11]   File "/usr/lib/python3.10/http/client.py", line 1277, in endheaders
[15/07/2023 18:54:11]     self._send_output(message_body, encode_chunked=encode_chunked)
[15/07/2023 18:54:11]   File "/usr/lib/python3.10/http/client.py", line 1037, in _send_output
[15/07/2023 18:54:11]     self.send(msg)
[15/07/2023 18:54:11]   File "/usr/lib/python3.10/http/client.py", line 975, in send
[15/07/2023 18:54:11]     self.connect()
[15/07/2023 18:54:11]   File "/home/sgautam/.local/lib/python3.10/site-packages/urllib3/connection.py", line 205, in connect
[15/07/2023 18:54:11]     conn = self._new_conn()
[15/07/2023 18:54:11]   File "/home/sgautam/.local/lib/python3.10/site-packages/urllib3/connection.py", line 186, in _new_conn
[15/07/2023 18:54:11]     raise NewConnectionError(
[15/07/2023 18:54:11] urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x7f3f07394430>: Failed to establish a new connection: [Errno 111] Connection refused
[15/07/2023 18:54:11] 
[15/07/2023 18:54:11] During handling of the above exception, another exception occurred:
[15/07/2023 18:54:11] 
[15/07/2023 18:54:11] Traceback (most recent call last):
[15/07/2023 18:54:11]   File "/home/sgautam/.local/lib/python3.10/site-packages/requests/adapters.py", line 486, in send
[15/07/2023 18:54:11]     resp = conn.urlopen(
[15/07/2023 18:54:11]   File "/home/sgautam/.local/lib/python3.10/site-packages/urllib3/connectionpool.py", line 798, in urlopen
[15/07/2023 18:54:11]     retries = retries.increment(
[15/07/2023 18:54:11]   File "/home/sgautam/.local/lib/python3.10/site-packages/urllib3/util/retry.py", line 592, in increment
[15/07/2023 18:54:11]     raise MaxRetryError(_pool, url, error or ResponseError(cause))
[15/07/2023 18:54:11] urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='localhost', port=8888): Max retries exceeded with url: /druid/v2/sql (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f3f07394430>: Failed to establish a new connection: [Errno 111] Connection refused'))
[15/07/2023 18:54:11] 
[15/07/2023 18:54:11] During handling of the above exception, another exception occurred:
[15/07/2023 18:54:11] 
[15/07/2023 18:54:11] Traceback (most recent call last):
[15/07/2023 18:54:11]   File "/mnt/c/Users/winga/OneDrive/Desktop/repos/KDL_SRIP23/data_ingestion/csv_from_druid.py", line 13, in <module>
[15/07/2023 18:54:11]     result = pydruid_helper.ExecuteSQLQueryGetCSV(sys.argv[1])
[15/07/2023 18:54:11]   File "/mnt/c/Users/winga/OneDrive/Desktop/repos/KDL_SRIP23/data_ingestion/pydruid_helper.py", line 17, in ExecuteSQLQueryGetCSV
[15/07/2023 18:54:11]     csv = requests.post(druid_url, json={"query": query, "resultFormat": "csv", "header": True}).text
[15/07/2023 18:54:11]   File "/home/sgautam/.local/lib/python3.10/site-packages/requests/api.py", line 115, in post
[15/07/2023 18:54:11]     return request("post", url, data=data, json=json, **kwargs)
[15/07/2023 18:54:11]   File "/home/sgautam/.local/lib/python3.10/site-packages/requests/api.py", line 59, in request
[15/07/2023 18:54:11]     return session.request(method=method, url=url, **kwargs)
[15/07/2023 18:54:11]   File "/home/sgautam/.local/lib/python3.10/site-packages/requests/sessions.py", line 589, in request
[15/07/2023 18:54:11]     resp = self.send(prep, **send_kwargs)
[15/07/2023 18:54:11]   File "/home/sgautam/.local/lib/python3.10/site-packages/requests/sessions.py", line 703, in send
[15/07/2023 18:54:11]     r = adapter.send(request, **kwargs)
[15/07/2023 18:54:11]   File "/home/sgautam/.local/lib/python3.10/site-packages/requests/adapters.py", line 519, in send
[15/07/2023 18:54:11]     raise ConnectionError(e, request=request)
[15/07/2023 18:54:11] requests.exceptions.ConnectionError: HTTPConnectionPool(host='localhost', port=8888): Max retries exceeded with url: /druid/v2/sql (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f3f07394430>: Failed to establish a new connection: [Errno 111] Connection refused'))
[15/07/2023 18:54:11] 
[15/07/2023 18:54:11] ***
[15/07/2023 18:54:49] *** EXCEPTION ***
[15/07/2023 18:54:49] Traceback (most recent call last):
[15/07/2023 18:54:49]   File "/home/sgautam/.local/lib/python3.10/site-packages/urllib3/connection.py", line 174, in _new_conn
[15/07/2023 18:54:49]     conn = connection.create_connection(
[15/07/2023 18:54:49]   File "/home/sgautam/.local/lib/python3.10/site-packages/urllib3/util/connection.py", line 95, in create_connection
[15/07/2023 18:54:49]     raise err
[15/07/2023 18:54:49]   File "/home/sgautam/.local/lib/python3.10/site-packages/urllib3/util/connection.py", line 85, in create_connection
[15/07/2023 18:54:49]     sock.connect(sa)
[15/07/2023 18:54:49] ConnectionRefusedError: [Errno 111] Connection refused
[15/07/2023 18:54:49] 
[15/07/2023 18:54:49] During handling of the above exception, another exception occurred:
[15/07/2023 18:54:49] 
[15/07/2023 18:54:49] Traceback (most recent call last):
[15/07/2023 18:54:49]   File "/home/sgautam/.local/lib/python3.10/site-packages/urllib3/connectionpool.py", line 714, in urlopen
[15/07/2023 18:54:49]     httplib_response = self._make_request(
[15/07/2023 18:54:49]   File "/home/sgautam/.local/lib/python3.10/site-packages/urllib3/connectionpool.py", line 415, in _make_request
[15/07/2023 18:54:49]     conn.request(method, url, **httplib_request_kw)
[15/07/2023 18:54:49]   File "/home/sgautam/.local/lib/python3.10/site-packages/urllib3/connection.py", line 244, in request
[15/07/2023 18:54:49]     super(HTTPConnection, self).request(method, url, body=body, headers=headers)
[15/07/2023 18:54:49]   File "/usr/lib/python3.10/http/client.py", line 1282, in request
[15/07/2023 18:54:49]     self._send_request(method, url, body, headers, encode_chunked)
[15/07/2023 18:54:49]   File "/usr/lib/python3.10/http/client.py", line 1328, in _send_request
[15/07/2023 18:54:49]     self.endheaders(body, encode_chunked=encode_chunked)
[15/07/2023 18:54:49]   File "/usr/lib/python3.10/http/client.py", line 1277, in endheaders
[15/07/2023 18:54:49]     self._send_output(message_body, encode_chunked=encode_chunked)
[15/07/2023 18:54:49]   File "/usr/lib/python3.10/http/client.py", line 1037, in _send_output
[15/07/2023 18:54:49]     self.send(msg)
[15/07/2023 18:54:49]   File "/usr/lib/python3.10/http/client.py", line 975, in send
[15/07/2023 18:54:49]     self.connect()
[15/07/2023 18:54:49]   File "/home/sgautam/.local/lib/python3.10/site-packages/urllib3/connection.py", line 205, in connect
[15/07/2023 18:54:49]     conn = self._new_conn()
[15/07/2023 18:54:49]   File "/home/sgautam/.local/lib/python3.10/site-packages/urllib3/connection.py", line 186, in _new_conn
[15/07/2023 18:54:49]     raise NewConnectionError(
[15/07/2023 18:54:49] urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x7f175d2a0430>: Failed to establish a new connection: [Errno 111] Connection refused
[15/07/2023 18:54:49] 
[15/07/2023 18:54:49] During handling of the above exception, another exception occurred:
[15/07/2023 18:54:49] 
[15/07/2023 18:54:49] Traceback (most recent call last):
[15/07/2023 18:54:49]   File "/home/sgautam/.local/lib/python3.10/site-packages/requests/adapters.py", line 486, in send
[15/07/2023 18:54:49]     resp = conn.urlopen(
[15/07/2023 18:54:49]   File "/home/sgautam/.local/lib/python3.10/site-packages/urllib3/connectionpool.py", line 798, in urlopen
[15/07/2023 18:54:49]     retries = retries.increment(
[15/07/2023 18:54:49]   File "/home/sgautam/.local/lib/python3.10/site-packages/urllib3/util/retry.py", line 592, in increment
[15/07/2023 18:54:49]     raise MaxRetryError(_pool, url, error or ResponseError(cause))
[15/07/2023 18:54:49] urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='localhost', port=8888): Max retries exceeded with url: /druid/v2/sql (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f175d2a0430>: Failed to establish a new connection: [Errno 111] Connection refused'))
[15/07/2023 18:54:49] 
[15/07/2023 18:54:49] During handling of the above exception, another exception occurred:
[15/07/2023 18:54:49] 
[15/07/2023 18:54:49] Traceback (most recent call last):
[15/07/2023 18:54:49]   File "/mnt/c/Users/winga/OneDrive/Desktop/repos/KDL_SRIP23/data_ingestion/csv_from_druid.py", line 13, in <module>
[15/07/2023 18:54:49]     result = pydruid_helper.ExecuteSQLQueryGetCSV(sys.argv[1])
[15/07/2023 18:54:49]   File "/mnt/c/Users/winga/OneDrive/Desktop/repos/KDL_SRIP23/data_ingestion/pydruid_helper.py", line 17, in ExecuteSQLQueryGetCSV
[15/07/2023 18:54:49]     csv = requests.post(druid_url, json={"query": query, "resultFormat": "csv", "header": True}).text
[15/07/2023 18:54:49]   File "/home/sgautam/.local/lib/python3.10/site-packages/requests/api.py", line 115, in post
[15/07/2023 18:54:49]     return request("post", url, data=data, json=json, **kwargs)
[15/07/2023 18:54:49]   File "/home/sgautam/.local/lib/python3.10/site-packages/requests/api.py", line 59, in request
[15/07/2023 18:54:49]     return session.request(method=method, url=url, **kwargs)
[15/07/2023 18:54:49]   File "/home/sgautam/.local/lib/python3.10/site-packages/requests/sessions.py", line 589, in request
[15/07/2023 18:54:49]     resp = self.send(prep, **send_kwargs)
[15/07/2023 18:54:49]   File "/home/sgautam/.local/lib/python3.10/site-packages/requests/sessions.py", line 703, in send
[15/07/2023 18:54:49]     r = adapter.send(request, **kwargs)
[15/07/2023 18:54:49]   File "/home/sgautam/.local/lib/python3.10/site-packages/requests/adapters.py", line 519, in send
[15/07/2023 18:54:49]     raise ConnectionError(e, request=request)
[15/07/2023 18:54:49] requests.exceptions.ConnectionError: HTTPConnectionPool(host='localhost', port=8888): Max retries exceeded with url: /druid/v2/sql (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f175d2a0430>: Failed to establish a new connection: [Errno 111] Connection refused'))
[15/07/2023 18:54:49] 
[15/07/2023 18:54:49] ***
[15/07/2023 18:55:41] *** EXCEPTION ***
[15/07/2023 18:55:41] Traceback (most recent call last):
[15/07/2023 18:55:41]   File "/home/sgautam/.local/lib/python3.10/site-packages/urllib3/connection.py", line 174, in _new_conn
[15/07/2023 18:55:41]     conn = connection.create_connection(
[15/07/2023 18:55:41]   File "/home/sgautam/.local/lib/python3.10/site-packages/urllib3/util/connection.py", line 95, in create_connection
[15/07/2023 18:55:41]     raise err
[15/07/2023 18:55:41]   File "/home/sgautam/.local/lib/python3.10/site-packages/urllib3/util/connection.py", line 85, in create_connection
[15/07/2023 18:55:41]     sock.connect(sa)
[15/07/2023 18:55:41] ConnectionRefusedError: [Errno 111] Connection refused
[15/07/2023 18:55:41] 
[15/07/2023 18:55:41] During handling of the above exception, another exception occurred:
[15/07/2023 18:55:41] 
[15/07/2023 18:55:41] Traceback (most recent call last):
[15/07/2023 18:55:41]   File "/home/sgautam/.local/lib/python3.10/site-packages/urllib3/connectionpool.py", line 714, in urlopen
[15/07/2023 18:55:41]     httplib_response = self._make_request(
[15/07/2023 18:55:41]   File "/home/sgautam/.local/lib/python3.10/site-packages/urllib3/connectionpool.py", line 415, in _make_request
[15/07/2023 18:55:41]     conn.request(method, url, **httplib_request_kw)
[15/07/2023 18:55:41]   File "/home/sgautam/.local/lib/python3.10/site-packages/urllib3/connection.py", line 244, in request
[15/07/2023 18:55:41]     super(HTTPConnection, self).request(method, url, body=body, headers=headers)
[15/07/2023 18:55:41]   File "/usr/lib/python3.10/http/client.py", line 1282, in request
[15/07/2023 18:55:41]     self._send_request(method, url, body, headers, encode_chunked)
[15/07/2023 18:55:41]   File "/usr/lib/python3.10/http/client.py", line 1328, in _send_request
[15/07/2023 18:55:41]     self.endheaders(body, encode_chunked=encode_chunked)
[15/07/2023 18:55:41]   File "/usr/lib/python3.10/http/client.py", line 1277, in endheaders
[15/07/2023 18:55:41]     self._send_output(message_body, encode_chunked=encode_chunked)
[15/07/2023 18:55:41]   File "/usr/lib/python3.10/http/client.py", line 1037, in _send_output
[15/07/2023 18:55:41]     self.send(msg)
[15/07/2023 18:55:41]   File "/usr/lib/python3.10/http/client.py", line 975, in send
[15/07/2023 18:55:41]     self.connect()
[15/07/2023 18:55:41]   File "/home/sgautam/.local/lib/python3.10/site-packages/urllib3/connection.py", line 205, in connect
[15/07/2023 18:55:41]     conn = self._new_conn()
[15/07/2023 18:55:41]   File "/home/sgautam/.local/lib/python3.10/site-packages/urllib3/connection.py", line 186, in _new_conn
[15/07/2023 18:55:41]     raise NewConnectionError(
[15/07/2023 18:55:41] urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x7fc88948c430>: Failed to establish a new connection: [Errno 111] Connection refused
[15/07/2023 18:55:41] 
[15/07/2023 18:55:41] During handling of the above exception, another exception occurred:
[15/07/2023 18:55:41] 
[15/07/2023 18:55:41] Traceback (most recent call last):
[15/07/2023 18:55:41]   File "/home/sgautam/.local/lib/python3.10/site-packages/requests/adapters.py", line 486, in send
[15/07/2023 18:55:41]     resp = conn.urlopen(
[15/07/2023 18:55:41]   File "/home/sgautam/.local/lib/python3.10/site-packages/urllib3/connectionpool.py", line 798, in urlopen
[15/07/2023 18:55:41]     retries = retries.increment(
[15/07/2023 18:55:41]   File "/home/sgautam/.local/lib/python3.10/site-packages/urllib3/util/retry.py", line 592, in increment
[15/07/2023 18:55:41]     raise MaxRetryError(_pool, url, error or ResponseError(cause))
[15/07/2023 18:55:41] urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='localhost', port=8888): Max retries exceeded with url: /druid/v2/sql (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7fc88948c430>: Failed to establish a new connection: [Errno 111] Connection refused'))
[15/07/2023 18:55:41] 
[15/07/2023 18:55:41] During handling of the above exception, another exception occurred:
[15/07/2023 18:55:41] 
[15/07/2023 18:55:41] Traceback (most recent call last):
[15/07/2023 18:55:41]   File "/mnt/c/Users/winga/OneDrive/Desktop/repos/KDL_SRIP23/data_ingestion/csv_from_druid.py", line 13, in <module>
[15/07/2023 18:55:41]     result = pydruid_helper.ExecuteSQLQueryGetCSV(sys.argv[1])
[15/07/2023 18:55:41]   File "/mnt/c/Users/winga/OneDrive/Desktop/repos/KDL_SRIP23/data_ingestion/pydruid_helper.py", line 17, in ExecuteSQLQueryGetCSV
[15/07/2023 18:55:41]     csv = requests.post(druid_url, json={"query": query, "resultFormat": "csv", "header": True}).text
[15/07/2023 18:55:41]   File "/home/sgautam/.local/lib/python3.10/site-packages/requests/api.py", line 115, in post
[15/07/2023 18:55:41]     return request("post", url, data=data, json=json, **kwargs)
[15/07/2023 18:55:41]   File "/home/sgautam/.local/lib/python3.10/site-packages/requests/api.py", line 59, in request
[15/07/2023 18:55:41]     return session.request(method=method, url=url, **kwargs)
[15/07/2023 18:55:41]   File "/home/sgautam/.local/lib/python3.10/site-packages/requests/sessions.py", line 589, in request
[15/07/2023 18:55:41]     resp = self.send(prep, **send_kwargs)
[15/07/2023 18:55:41]   File "/home/sgautam/.local/lib/python3.10/site-packages/requests/sessions.py", line 703, in send
[15/07/2023 18:55:41]     r = adapter.send(request, **kwargs)
[15/07/2023 18:55:41]   File "/home/sgautam/.local/lib/python3.10/site-packages/requests/adapters.py", line 519, in send
[15/07/2023 18:55:41]     raise ConnectionError(e, request=request)
[15/07/2023 18:55:41] requests.exceptions.ConnectionError: HTTPConnectionPool(host='localhost', port=8888): Max retries exceeded with url: /druid/v2/sql (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7fc88948c430>: Failed to establish a new connection: [Errno 111] Connection refused'))
[15/07/2023 18:55:41] 
[15/07/2023 18:55:41] ***
[15/07/2023 18:56:58] *** EXCEPTION ***
[15/07/2023 18:56:58] Traceback (most recent call last):
[15/07/2023 18:56:58]   File "/home/sgautam/.local/lib/python3.10/site-packages/urllib3/connection.py", line 174, in _new_conn
[15/07/2023 18:56:58]     conn = connection.create_connection(
[15/07/2023 18:56:58]   File "/home/sgautam/.local/lib/python3.10/site-packages/urllib3/util/connection.py", line 95, in create_connection
[15/07/2023 18:56:58]     raise err
[15/07/2023 18:56:58]   File "/home/sgautam/.local/lib/python3.10/site-packages/urllib3/util/connection.py", line 85, in create_connection
[15/07/2023 18:56:58]     sock.connect(sa)
[15/07/2023 18:56:58] ConnectionRefusedError: [Errno 111] Connection refused
[15/07/2023 18:56:58] 
[15/07/2023 18:56:58] During handling of the above exception, another exception occurred:
[15/07/2023 18:56:58] 
[15/07/2023 18:56:58] Traceback (most recent call last):
[15/07/2023 18:56:58]   File "/home/sgautam/.local/lib/python3.10/site-packages/urllib3/connectionpool.py", line 714, in urlopen
[15/07/2023 18:56:58]     httplib_response = self._make_request(
[15/07/2023 18:56:58]   File "/home/sgautam/.local/lib/python3.10/site-packages/urllib3/connectionpool.py", line 415, in _make_request
[15/07/2023 18:56:58]     conn.request(method, url, **httplib_request_kw)
[15/07/2023 18:56:58]   File "/home/sgautam/.local/lib/python3.10/site-packages/urllib3/connection.py", line 244, in request
[15/07/2023 18:56:58]     super(HTTPConnection, self).request(method, url, body=body, headers=headers)
[15/07/2023 18:56:58]   File "/usr/lib/python3.10/http/client.py", line 1282, in request
[15/07/2023 18:56:58]     self._send_request(method, url, body, headers, encode_chunked)
[15/07/2023 18:56:58]   File "/usr/lib/python3.10/http/client.py", line 1328, in _send_request
[15/07/2023 18:56:58]     self.endheaders(body, encode_chunked=encode_chunked)
[15/07/2023 18:56:58]   File "/usr/lib/python3.10/http/client.py", line 1277, in endheaders
[15/07/2023 18:56:58]     self._send_output(message_body, encode_chunked=encode_chunked)
[15/07/2023 18:56:58]   File "/usr/lib/python3.10/http/client.py", line 1037, in _send_output
[15/07/2023 18:56:58]     self.send(msg)
[15/07/2023 18:56:58]   File "/usr/lib/python3.10/http/client.py", line 975, in send
[15/07/2023 18:56:58]     self.connect()
[15/07/2023 18:56:58]   File "/home/sgautam/.local/lib/python3.10/site-packages/urllib3/connection.py", line 205, in connect
[15/07/2023 18:56:58]     conn = self._new_conn()
[15/07/2023 18:56:58]   File "/home/sgautam/.local/lib/python3.10/site-packages/urllib3/connection.py", line 186, in _new_conn
[15/07/2023 18:56:58]     raise NewConnectionError(
[15/07/2023 18:56:58] urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x7f365f59c430>: Failed to establish a new connection: [Errno 111] Connection refused
[15/07/2023 18:56:58] 
[15/07/2023 18:56:58] During handling of the above exception, another exception occurred:
[15/07/2023 18:56:58] 
[15/07/2023 18:56:58] Traceback (most recent call last):
[15/07/2023 18:56:58]   File "/home/sgautam/.local/lib/python3.10/site-packages/requests/adapters.py", line 486, in send
[15/07/2023 18:56:58]     resp = conn.urlopen(
[15/07/2023 18:56:58]   File "/home/sgautam/.local/lib/python3.10/site-packages/urllib3/connectionpool.py", line 798, in urlopen
[15/07/2023 18:56:58]     retries = retries.increment(
[15/07/2023 18:56:58]   File "/home/sgautam/.local/lib/python3.10/site-packages/urllib3/util/retry.py", line 592, in increment
[15/07/2023 18:56:58]     raise MaxRetryError(_pool, url, error or ResponseError(cause))
[15/07/2023 18:56:58] urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='localhost', port=8888): Max retries exceeded with url: /druid/v2/sql (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f365f59c430>: Failed to establish a new connection: [Errno 111] Connection refused'))
[15/07/2023 18:56:58] 
[15/07/2023 18:56:58] During handling of the above exception, another exception occurred:
[15/07/2023 18:56:58] 
[15/07/2023 18:56:58] Traceback (most recent call last):
[15/07/2023 18:56:58]   File "/mnt/c/Users/winga/OneDrive/Desktop/repos/KDL_SRIP23/data_ingestion/csv_from_druid.py", line 19, in <module>
[15/07/2023 18:56:58]     result = pydruid_helper.ExecuteSQLQueryGetCSV(sys.argv[1])
[15/07/2023 18:56:58]   File "/mnt/c/Users/winga/OneDrive/Desktop/repos/KDL_SRIP23/data_ingestion/pydruid_helper.py", line 17, in ExecuteSQLQueryGetCSV
[15/07/2023 18:56:58]     csv = requests.post(druid_url, json={"query": query, "resultFormat": "csv", "header": True}).text
[15/07/2023 18:56:58]   File "/home/sgautam/.local/lib/python3.10/site-packages/requests/api.py", line 115, in post
[15/07/2023 18:56:58]     return request("post", url, data=data, json=json, **kwargs)
[15/07/2023 18:56:58]   File "/home/sgautam/.local/lib/python3.10/site-packages/requests/api.py", line 59, in request
[15/07/2023 18:56:58]     return session.request(method=method, url=url, **kwargs)
[15/07/2023 18:56:58]   File "/home/sgautam/.local/lib/python3.10/site-packages/requests/sessions.py", line 589, in request
[15/07/2023 18:56:58]     resp = self.send(prep, **send_kwargs)
[15/07/2023 18:56:58]   File "/home/sgautam/.local/lib/python3.10/site-packages/requests/sessions.py", line 703, in send
[15/07/2023 18:56:58]     r = adapter.send(request, **kwargs)
[15/07/2023 18:56:58]   File "/home/sgautam/.local/lib/python3.10/site-packages/requests/adapters.py", line 519, in send
[15/07/2023 18:56:58]     raise ConnectionError(e, request=request)
[15/07/2023 18:56:58] requests.exceptions.ConnectionError: HTTPConnectionPool(host='localhost', port=8888): Max retries exceeded with url: /druid/v2/sql (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f365f59c430>: Failed to establish a new connection: [Errno 111] Connection refused'))
[15/07/2023 18:56:58] 
[15/07/2023 18:56:58] ***
